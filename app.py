# =======================
# 1. Import å€ (ã€ä¿®æ”¹è™•ï¼šä¾åŠŸèƒ½åˆ†é¡æ•´ç† importã€‘)
# =======================
import os
import glob
import json
import ast
from datetime import datetime, timedelta

# ç¬¬ä¸‰æ–¹åº«
import pandas as pd
import numpy as np
import requests
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import plotly.io as pio
import plotly.express as px
import matplotlib.pyplot as plt
import streamlit as st
from streamlit_plotly_events import plotly_events
from st_aggrid import AgGrid, GridOptionsBuilder, GridUpdateMode
import pydeck as pdk
from itertools import product
import pytz
import base64
import re
import numpy as np
from wordcloud import WordCloud
import matplotlib.pyplot as plt
from PIL import Image, ImageDraw
import random
from collections import Counter
import streamlit.components.v1 as components
from streamlit.components.v1 import html
from io import StringIO
import hashlib
import schedule
import time
import threading
import logging
import shutil
from streamlit.web.server import Server
from tornado.web import Application, RequestHandler
from tornado.routing import Rule, PathMatches
import gc

#from fastapi import FastAPI
#from fastapi.responses import JSONResponse
#import uvicorn
#import threading
#
## =============================
## ğŸ” å»ºç«‹ FastAPI Server
## =============================
#api = FastAPI()
shared_data = {"project_rank": pd.DataFrame()}  # å…¨åŸŸå„²å­˜
#
#@api.get("/api/project_rank")
#def get_project_rank():
#    return JSONResponse(
#        content=shared_data["project_rank"].to_dict(orient="records"),
#        media_type="application/json",  # æ˜ç¢ºæŒ‡å®š MIME
#        headers={
#            "Cache-Control": "no-store, no-cache, must-revalidate, max-age=0",
#            "Pragma": "no-cache",
#            "Expires": "0"
#        }
#    )
#
#def run_api():
#    uvicorn.run(api)
    #uvicorn.run(api, host="0.0.0.0", port=8000)

# èƒŒæ™¯é–‹å•Ÿ API Server
#api_thread = threading.Thread(target=run_api, daemon=True)
#api_thread.start()
# threading.Thread(target=run_api, daemon=True).start()

# è‡ªè¨‚å‡½å¼èˆ‡è®Šæ•¸ï¼ˆä¾éœ€æ±‚èª¿æ•´ï¼Œè«‹æ ¹æ“šå¯¦éš›æƒ…æ³ä¿®æ”¹æ­¤è™• importï¼‰
from function import (
    data_root,
    today,
    last_scan_time,
    df_scan,
    df_light,
    df_click_lig,
    function_import_error,
)
if function_import_error:
    st.error(f"ğŸš¨ {function_import_error}")
    st.stop()

# è¨­å®šæ—¥èªŒä»¥ä¾¿é™¤éŒ¯
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(message)s')
logger = logging.getLogger(__name__)

# =======================
# 1.5. Custom JSON Route for Streamlit
# =======================
#class ProjectRankHandler(RequestHandler):
#    def get(self):
#        try:
#            # Retrieve project_rank from session state
#            project_rank = st.session_state.get("project_rank", pd.DataFrame())
#            if project_rank.empty:
#                logger.warning("project_rank is empty")
#                self.set_status(404)
#                self.write({"error": "No project rank data available"})
#                return
#
#            # Convert DataFrame to JSON
#            json_data = project_rank.to_dict(orient="records")
#            self.set_header("Content-Type", "application/json")
#            self.set_header("Cache-Control", "no-store, no-cache, must-revalidate, max-age=0")
#            self.set_header("Pragma", "no-cache")
#            self.set_header("Expires", "0")
#            self.write(json.dumps(json_data))
#        except Exception as e:
#            logger.error(f"Error in ProjectRankHandler: {e}")
#            self.set_status(500)
#            self.write({"error": str(e)})
#
#def add_custom_routes():
#    server = Server.get_current()
#    app = server._app
#    app.add_handlers(r".*", [(r"/api/project_rank", ProjectRankHandler)])
#
## Call this after Streamlit server starts
#add_custom_routes()

# =======================
# 2. åŸºæœ¬é…ç½®èˆ‡å¸¸æ•¸ (ã€ä¿®æ”¹è™•ï¼šå®šç¾© page config èˆ‡å¸¸æ•¸ã€‘)
# =======================
st.set_page_config(page_title="LiG Dashboard",layout="wide",)
TOKEN_FILE = "auth_token.json"  # æœ¬åœ°æ–‡ä»¶ä¿å­˜ Token çš„è·¯å¾‘
taipei_tz = pytz.timezone("Asia/Taipei")    # è¨­ç½®å°åŒ—æ™‚å€
CORE_API_SERVER = "https://api.lig.com.tw"
DASHBOARD_AGENT = "LigDashboard"
project_filepath = os.path.join("data", "projects_new_0306.csv")

@st.cache_resource()
def setup_api_handler(uri, handler):
    # Get instance of Tornado Application
    tornado_app = next(o for o in gc.get_referrers(Application) if o.__class__ is Application)
    # Insert custom handler
    tornado_app.wildcard_router.rules.insert(0, Rule(PathMatches(uri), handler))

class ProjectRankHandler(RequestHandler):
    def get(self):
        try:
            # Retrieve project_rank from session state
            project_rank = shared_data.get("project_rank", pd.DataFrame())
            if project_rank.empty:
                logger.warning("project_rank is empty")
                print("ğŸš¨ project_rank =")
                print(project_rank.head()) 
                self.set_status(500)
                self.write(json.dumps({"error": str(e)}))
                #st.error({"error": "No project rank data available"})
                #st.stop()

            # Convert DataFrame to JSON
            json_data = project_rank.to_dict(orient="records")
            # Set headers and write JSON response
            self.set_header("Content-Type", "application/json")
            self.set_header("Cache-Control", "no-store, no-cache, must-revalidate, max-age=0")
            self.set_header("Pragma", "no-cache")
            self.set_header("Expires", "0")
            self.write(json.dumps(json_data))
        except Exception as e:
            logger.error(f"Error in API request: {e}")
            self.set_status(500)
            self.write(json.dumps({"error": str(e)}))

# Register the handler (this runs only once)
setup_api_handler('/api/project_rank', ProjectRankHandler)


today = datetime.now().date()
yesterday = today - timedelta(days=1)

start_of_this_month = today.replace(day=1)
startlast_month = (start_of_this_month - timedelta(days=1)).replace(day=1)
end_of_last_month = start_of_this_month - timedelta(days=1)

start_of_week = today - timedelta(days=today.weekday())
start_of_last_week = start_of_week - timedelta(days=7)
end_of_last_week = start_of_week - timedelta(days=1)
start_of_month = today.replace(day=1)
if today.month == 1:
    start_of_last_month = today.replace(year=today.year - 1, month=12, day=1)
else:
    start_of_last_month = today.replace(month=today.month - 1, day=1)
end_of_last_month = start_of_month - timedelta(days=1)

#====================================================
# 3. CSS æ¨£å¼å®šç¾©ï¼ˆæŠ½é›¢å¸¸æ•¸ï¼‰
#====================================================

BASE_CSS = """
    <style>
    .date-input-row {
    display: inline-block;
    height: 38px;
    width: 100%; /* æ ¹æ“šçˆ¶å®¹å™¨èª¿æ•´å¯¬åº¦ */
    padding: 5px 10px; /* å‚ç›´æ–¹å‘çš„å…§é‚Šè·ç¢ºä¿æ–‡å­—ç½®ä¸­ */
    font-size: 16px;
    line-height: 28px;  /* èª¿æ•´è¡Œé«˜ï¼Œèˆ‡æ¡†é«˜åº¦åŒ¹é… */
    color: #333;
    background-color: #96c5df;
    background-clip: padding-box;
    border: 0px solid #ccc;
    border-radius: 4px;
    box-shadow: inset 0 1px 2px rgba(0, 0, 0, 0.1);
    }
    .date-input-row label {
        margin-right: 10px;
        font-weight: bold;
        white-space: nowrap;
    }
    .date-input-row input {
        flex: 1;
    }
    .page-title {
        background-color: #fff;
        text-align: right;
        box-shadow: none;
        padding: 5px 0;
    }
    .page-title-center {
        background-color: #fff;
        text-align: left;
        box-shadow: none;
        padding: 5px 0;
    }
    .orange-label-row {
        background-color: orange;
        color: white;
        padding: 5px 10px;
        border-radius: 4px;
        font-weight: bold;
    }
    </style>
    """
st.markdown(BASE_CSS,unsafe_allow_html=True)

METRIC_CSS = """
    <style>
    .custom-metric {
        background-color: #f0f8ff; /* æ·¡è—è‰²èƒŒæ™¯ */
        padding: 10px;
        border-radius: 10px; /* åœ“è§’é‚Šæ¡† */
        text-align: center; /* ç½®ä¸­ */
        box-shadow: 0px 4px 6px rgba(0, 0, 0, 0.1); /* é™°å½±æ•ˆæœ */
        margin-bottom: 5px; /* èˆ‡å…¶ä»–å…ƒç´ çš„è·é›¢ */
    }
    .custom-metric h1 {
        margin: 0;
        font-size: 1.5em; /* èª¿æ•´æ•¸å­—å¤§å° */
        color: #333; /* æ•¸å­—é¡è‰² */
    }
    .custom-metric p1 {
        margin: 0;
        font-size: 1em; /* æ¨™é¡Œå¤§å° */
        color: #666; /* æ¨™é¡Œé¡è‰² */
    }
    .custom-metric p2 {
        margin: 0;
        font-size: 1em; /* æ¨™é¡Œå¤§å° */
        color: red; /* æ¨™é¡Œé¡è‰² */
    }
    </style>
    """
# metric css
st.markdown(METRIC_CSS,unsafe_allow_html=True)

st.markdown("""
    <style>
    div[data-testid="stElementContainer"] .stPlotlyChart {
        transform: scale(0.8) !important;  /* ä½¿ç”¨ !important æé«˜å„ªå…ˆç´š */
        transform-origin: top left;
        width: 125% !important;  /* è£œå„Ÿç¸®æ”¾ */
        height: auto !important;
    }
    div[data-testid="stElementContainer"] .plot-container {
        transform: scale(0.8) !important;
        transform-origin: top left;
    }
    </style>
""", unsafe_allow_html=True)

st.markdown(
    """
    <style>
    div.stButton > button {
        background-color: #4f9ac3; 
        color: white; /* ç™½è‰²æ–‡å­— */
        border: none;
        padding: 10px 20px;
        border-radius: 5px;
    }
    div.stButton > button:hover {
        background-color: #CC0000; /* æ‡¸åœæ™‚è®Šæš—çš„ç´…è‰² */
    }
    </style>
    """,
    unsafe_allow_html=True
)
# =======================
# 4. Session åˆå§‹åŒ– (ã€ä¿®æ”¹è™•ï¼šå°‡é è¨­ç‹€æ…‹é›†ä¸­ç®¡ç†ã€‘)
# =======================
def initialize():
    default_states = {
        'df_project': lambda: load_data(project_filepath),
        'df_scan': df_scan,
        'df_click_lig': df_click_lig,
        'editing_row_index': None,
        '_lig_token': "",
        'scenes_option': [],
        'light_ids_option': [],
        'coordinates_list_option': [],
        'project_name_new': "",
        'start_date_new': pd.to_datetime("today").date(),
        'end_date_new': pd.to_datetime("today").date(),
        'is_active_new': False,
        'lat_lon_new': "",
        'light_ids_input_new': [],
        'coordinates_list': [],
        'coordinates_input_new': [],
        'scenes_input_new': [],
        'experiment_number': 0,
        'interaction_number': 0,
        'rerun_triggered': False,
        'participants_number': False,
        'merge_data':None,
        'merge_datefilter':None,
        'project_rank':None,
        'email_options':[]
    }

    for key, default in default_states.items():
        if key not in st.session_state:
            value = default() if callable(default) else default
            st.session_state[key] = value

# =======================
# 5. GET Data
# =======================
@st.cache_data
def prepare_project_data_all_time(df_prj, df_scan):
    # å®šç¾©å®‰å…¨è§£æ Light ID çš„å‡½å¼
    def parse_light_id(value):
        if isinstance(value, str):
            try:
                return json.loads(value)
            except json.JSONDecodeError:
                return None  # è‹¥è§£æå¤±æ•—ï¼Œè¿”å› None
        return value

    df_prj = df_prj.copy()
    df_prj["Light ID"] = df_prj["Light ID"].apply(parse_light_id)
    df_prj_exploded = df_prj.explode("Light ID").copy()
    df_prj_exploded["Light ID"] = df_prj_exploded["Light ID"].astype(str)

    # âŒ ä¸å†éæ¿¾æ™‚é–“
    df_scan_all = df_scan.copy()

    # åˆä½µè³‡æ–™
    merge_data = df_scan_all.merge(
        df_prj_exploded,
        left_on="lig_id",
        right_on="Light ID",
        how="inner"
    )
    
    return merge_data

@st.cache_data
def prepare_project_data(df_prj, df_scan, start_date, end_date):
    # å®šç¾©å®‰å…¨è§£æ Light ID çš„å‡½å¼
    def parse_light_id(value):
        if isinstance(value, str):
            try:
                return json.loads(value)
            except json.JSONDecodeError:
                return None  # è‹¥è§£æå¤±æ•—ï¼Œè¿”å› None
        return value
    df_prj = df_prj.copy()
    df_prj["Light ID"] = df_prj["Light ID"].apply(parse_light_id)
    df_prj_exploded = df_prj.explode("Light ID").copy()
    df_prj_exploded["Light ID"] = df_prj_exploded["Light ID"].astype(str)
    df_scan_filtered = df_date_filter(df_scan, 'scantime', start_date, end_date)
    
    merge_data = df_scan_filtered.merge(
        df_prj_exploded,
        left_on="lig_id",
        right_on="Light ID",
        how="inner"
    )
    
    return merge_data

def fetch_data_from_server(endpoint, token_key="_lig_token"):
    url = f"{CORE_API_SERVER}/{endpoint}"
    token = st.session_state.get(token_key, "")
    headers = {
        "Authorization": f"Bearer {token}",
        "User-Agent": f"{DASHBOARD_AGENT}/0.1",
    }
    try:
        response = requests.get(url, headers=headers)
        response.raise_for_status()
        return response.json()
    except requests.exceptions.RequestException as e:
        st.error(f"Error fetching data from {url}: {e}")
        return {}

def get_coordianate_dict_from_server():
    data = fetch_data_from_server('api/v1/coordinate_systems', token_key="_lig_token").get('coordinate_systems',[])
    return pd.DataFrame(data)

@st.cache_data
def generate_heatmap_data(df):
     # ä¾æ“šåˆä½µå¾Œè³‡æ–™ç”¢ç”Ÿç†±åŠ›åœ–æ‰€éœ€çš„è³‡æ–™
    scan_lonlat = df.copy()
    lat_lon_split = scan_lonlat["Latitude and Longitude"].str.split(",", expand=True)
    scan_lonlat["prj_lat"] = lat_lon_split[0].astype(float)
    scan_lonlat["prj_lon"] = lat_lon_split[1].astype(float)
    df_heatmap = scan_lonlat.groupby("Project Name").agg(
        Scan_Count=("Project Name", "size"),
        prj_lon=("prj_lon", "first"),
        prj_lat=("prj_lat", "first")
    ).reset_index()
    return df_heatmap[['prj_lon', 'prj_lat', 'Scan_Count']].reset_index(drop=True)

@st.cache_data
def fetch_ar_objects(scene_id):
    ar_obj = fetch_data_from_server(f'api/v1/cms_ar_objects_from_scene/{scene_id}', token_key="_lig_token").get('ar_objects',[])
    return ar_obj

@st.cache_data
def get_ar_objects_by_scene_id(scene_id,df_scenelist, token=None):
    url = f"{CORE_API_SERVER}/api/v1/ar_objects_from_scene/{scene_id}"
    headers = {"User-Agent": f"{DASHBOARD_AGENT}/0.1"}
    if token:
        headers["Authorization"] = f"Bearer {token}"
    try:
        response = requests.get(url, headers=headers)
        response.raise_for_status()
        data = response.json()
    except Exception as e:
        st.error(f"å–å¾— light_id {scene_id} è³‡æ–™éŒ¯èª¤ï¼š{e}")
        return []
    
    objects = []
    scene_id_str = str(scene_id)
    # ç²å–å ´æ™¯å­—å…¸
    scene_value = df_scenelist.loc[df_scenelist['Id'] == scene_id_str, 'Name'].iloc[0]
    # data ä¸­ key "scenes" å…§éƒ¨æ¯å€‹ scene å¯èƒ½åŒ…å« "ar_objects"
    for ar_obj in data.get("ar_objects", []):
        objects.append({
            "scene_id": scene_id,
            "scene": f'{scene_id}-{scene_value}',
            "obj_id": ar_obj.get("id"),
            "obj_name": ar_obj.get("name"),
            "location_x": ar_obj.get("location").get("x"),
            "location_y": ar_obj.get("location").get("y"),
            "location_z": ar_obj.get("location").get("z"),
        })
    return objects

def calculate_statistics(click_data, multiplier):
    click_number = int(len(click_data) *multiplier)
    user_number = int(click_data['user_id'].nunique() *multiplier)
    return click_number, user_number

def user_data_fig(df,start_date,end_date):
    date_range = [start_date + timedelta(days=x) for x in range((end_date - start_date).days + 1)]
    date_range = [d.strftime('%Y-%m-%d') for d in date_range]
    daily_users = (df.groupby(df['clicktime'].dt.strftime('%Y-%m-%d'))['user_id']
            .apply(lambda x: list(x.unique())).reset_index())
    daily_users.columns = ['date', 'user_id']
    # è¨ˆç®—æ¯å¤©çš„åƒèˆ‡äººæ•¸
    daily_users['daily_active_users'] = daily_users['user_id'].apply(len)
    all_users = set()  # è¿½è¹¤æ‰€æœ‰æ›¾å‡ºç¾çš„ç”¨æˆ¶
    new_users_count = []
    returning_users_count = []
    returning_ids_list = []

    for user_list in daily_users['user_id']:
        current_users = set(user_list)
        new_users = current_users - all_users  # æ–°å¢ç”¨æˆ¶
        returning_users = current_users & all_users  # å›è³¼ç”¨æˆ¶ï¼ˆèˆ‡ä¹‹å‰ç”¨æˆ¶çš„äº¤é›†ï¼‰
        
        new_users_count.append(len(new_users))
        returning_users_count.append(len(returning_users))
        returning_ids_list.append(list(returning_users))  # å„²å­˜å›è³¼ç”¨æˆ¶çš„ ID åˆ—è¡¨
        
        all_users.update(current_users)  # æ›´æ–°æ‰€æœ‰ç”¨æˆ¶é›†åˆ

    # æ•´åˆæ•¸æ“š
    daily_users['daily_active_users'] = daily_users['user_id'].apply(len)
    daily_users['new_users'] = new_users_count
    daily_users['returning_users'] = returning_users_count
    daily_users['returning_ids'] = returning_ids_list
    # è¨ˆç®—ç´¯ç©äººæ•¸
    daily_users['cumulative_users'] = [len(set(df[df['clicktime'].dt.strftime('%Y-%m-%d') <= date]['user_id'].unique())) 
                                for date in daily_users['date']]

    # ç”Ÿæˆå®Œæ•´æ—¥æœŸç¯„åœä¸¦åˆä½µ
    date_range = [start_date + timedelta(days=x) for x in range((end_date - start_date).days + 1)]
    date_range = [d.strftime('%Y-%m-%d') for d in date_range]
    result = pd.DataFrame({'date': date_range})
    result = result.merge(daily_users[['date', 'daily_active_users', 'new_users', 'returning_users', 'returning_ids','cumulative_users']], 
                    on='date', how='left')
    result['daily_active_users'] = result['daily_active_users'].fillna(0).astype(int)
    result['new_users'] = result['new_users'].fillna(0).astype(int)
    result['returning_users'] = result['returning_users'].fillna(0).astype(int)
    result['returning_ids'] = result['returning_ids'].apply(lambda x: x if isinstance(x, list) else [])
    result['cumulative_users'] = result['cumulative_users'].fillna(method='ffill').fillna(0).astype(int)  # å‘å‰å¡«å……ç´¯ç©äººæ•¸

    max_daily = max(result['new_users'] + result['returning_users'])
    max_cumulative = max(result['cumulative_users'])
    scale_factor = max_cumulative / max_daily  # è¨ˆç®—æ¯”ä¾‹å› å­

    # çµ±è¨ˆå›è³¼ç”¨æˆ¶çš„æ¬¡æ•¸
    returning_ids_flat = [user_id for sublist in result['returning_ids'] for user_id in sublist]  # å±•å¹³æ‰€æœ‰å›è³¼ ID
    returning_counts = Counter(returning_ids_flat)  # è¨ˆç®—æ¯å€‹ç”¨æˆ¶çš„å›è³¼æ¬¡æ•¸

    # è½‰ç‚º DataFrame ä¸¦æ’åº
    returning_ranking = pd.DataFrame(returning_counts.items(), columns=['user_id', 'return_count'])
    returning_ranking = returning_ranking.sort_values(by='return_count', ascending=False).reset_index(drop=True)

    # ä½¿ç”¨ go.Figure è£½ä½œåœ–è¡¨
    fig = make_subplots(specs=[[{"secondary_y": True}]])

    # æ·»åŠ æŸ±ç‹€åœ– - æ–°å¢äººæ•¸ï¼ˆä½œç‚ºåƒèˆ‡äººæ•¸çš„ä¸€éƒ¨åˆ†ï¼‰
    fig.add_trace(
        go.Bar(
            x=result['date'],
            y=result['new_users'],
            name="æ–°å¢äººæ•¸",
            marker_color='skyblue',
            text=result['new_users'],
            textposition='auto'
        ),
        secondary_y=False
    )

    # æ·»åŠ æŸ±ç‹€åœ– - å›è³¼äººæ•¸ï¼ˆç–ŠåŠ åœ¨æ–°å¢äººæ•¸ä¸Šï¼‰
    fig.add_trace(
        go.Bar(
            x=result['date'],
            y=result['returning_users'],
            name="å›è³¼äººæ•¸",
            marker_color='salmon',
            text=result['returning_users'],
            textposition='auto'
        ),
        secondary_y=False
    )

    # æ·»åŠ æŠ˜ç·šåœ– - ç´¯ç©äººæ•¸
    fig.add_trace(
        go.Scatter(
            x=result['date'],
            y=result['cumulative_users'],
            name="ç´¯ç©äººæ•¸",
            mode='lines+markers',
            line=dict(color='green', width=2),
            marker=dict(size=8),
            text=result['cumulative_users'],
            hovertemplate='%{text}'
        ),
        secondary_y=True
    )

    # æ›´æ–°ä½ˆå±€
    fig.update_layout(
        title=dict(text="æ¯æ—¥åƒèˆ‡äººæ•¸èˆ‡ç´¯ç©äººæ•¸", x=0.5, xanchor='center'),
        xaxis_title="æ—¥æœŸ",
        yaxis_title="æ¯æ—¥åƒèˆ‡äººæ•¸",
        barmode='stack',  # æŸ±ç‹€åœ–ç–ŠåŠ 
        legend=dict(x=0.01, y=0.99, bgcolor='rgba(255, 255, 255, 0.5)', bordercolor='black', borderwidth=1),
        hovermode="x unified",
        template="plotly_white"
    )

    # æ›´æ–° Y è»¸æ¨™ç±¤
    fig.update_yaxes(
        title_text="æ¯æ—¥åƒèˆ‡äººæ•¸", 
        secondary_y=False,
        range=[0, max_daily * 1.1],
        dtick=50
    )
    fig.update_yaxes(
        title_text="ç´¯ç©äººæ•¸", 
        secondary_y=True,
        range=[0, max_daily * scale_factor * 1.1],
        dtick=500
    )
    return daily_users, fig

def generate_user_id_ranking(df):
    # æŒ‰ user_id çµ±è¨ˆé»æ“Šæ¬¡æ•¸
    user_click_counts = df.groupby('user_id').size().reset_index(name='Click Count')
    # æŒ‰é»æ“Šæ¬¡æ•¸é™åºæ’åº
    user_click_counts = user_click_counts.sort_values(by='Click Count', ascending=False)
    return user_click_counts

def clickobjdist_with_userpath(fig,user_data, multiplier=1.0):    
    fig_ranking = fig
    user_data['clicktime'] = pd.to_datetime(user_data['clicktime'])
    user_data = user_data.sort_values('clicktime')
    selected_user = user_data['user_id'].iloc[0]  # é è¨­ç¬¬ä¸€å€‹ user_id
    if not user_data.empty:
        user_data['sequence'] = range(1, len(user_data) + 1)
        fig_ranking.add_trace(
            go.Scatter(
                x=user_data['location_x'],
                y=user_data['location_z'],
                mode='markers+lines+text',  # æ·»åŠ æ–‡å­—é¡¯ç¤ºé †åº
                marker=dict(
                    size=10,
                    color=user_data['sequence'],  # æ ¹æ“šé †åºæ¼¸è®Šé¡è‰²
                    colorscale='Blues',
                    showscale=True,
                    symbol='circle',
                    line=dict(width=1, color='black')  # åªä¿ç•™ä¸€å€‹ line å®šç¾©
                ),
                line=dict(width=2, color='gray', dash='dash'),  # è™›ç·šè¡¨ç¤ºè·¯å¾‘
                text=user_data['sequence'],  # åœ¨é»ä¸Šé¡¯ç¤ºé †åºè™Ÿ
                textposition='top center',
                textfont=dict(size=20, color='red'),
                hovertemplate=(
                    'Time: %{customdata[0]}<br>'
                    'Obj: %{customdata[1]}<br>'
                    'Sequence: %{text}<extra></extra>'
                ),
                customdata=user_data[['clicktime', 'obj_name']].values,
                name=f"Path of {selected_user}"
            )
        )
# æ›´æ–°åœ–è¡¨æ¨™é¡Œä¸¦å•Ÿç”¨åœ–ä¾‹
    fig_ranking.update_layout(
        title=f"Click Distribution with User Path for {selected_user or 'None'}",
        showlegend=True,
        xaxis=dict(
            range=[-10, 10],
            scaleanchor="y",
            scaleratio=1,
            tickangle=45
        ),
        yaxis=dict(
            range=[10, -10]
        ),
        width=600,
        height=600,
    )
    fig.update_layout(
    autosize=True
    )

    user_data['clicktime'] = user_data['clicktime'].dt.strftime('%Y-%m-%d %H:%M:%S')
    return fig_ranking, user_data

def generate_project_rank(merge_data, df_prj,merge_data_yesterday,merge_data_today):
    yesterday_scan_counts = merge_data_yesterday.groupby("Project Name").size().reset_index(name="Yesterday Scans")
    today_scan_counts = merge_data_today.groupby("Project Name").size().reset_index(name="Today Scans")
    scan_counts = merge_data.groupby("Project Name").size().reset_index(name="Scan Count")
    # å°‡ç¸½æƒææ¬¡æ•¸èˆ‡æ˜¨å¤©æƒææ¬¡æ•¸ merge åˆ° df_prj ä¸­ï¼Œç¼ºå¤±çš„éƒ¨åˆ†å¡« 0
    df_prj = (
        df_prj.merge(scan_counts, on="Project Name", how="left")
              .merge(yesterday_scan_counts, on="Project Name", how="left")
              .merge(today_scan_counts, on="Project Name", how="left")
              .fillna({"Scan Count": 0, "Yesterday Scans": 0, "Today Scans": 0})
    )
    # å›å‚³æ’åºå¾Œçš„çµæœï¼Œä¾æ“šç¸½æƒææ¬¡æ•¸æ’åº
    return df_prj[["Project Name", "Scan Count", "Yesterday Scans","Today Scans"]].sort_values(by="Scan Count", ascending=False)

def generate_project_rank_card(df_prj,
                          last_month, this_month,
                          last_week, this_week,
                          yesterday, today):
    def count_scans(df, col_name):
        return df.groupby("Project Name").size().reset_index(name=col_name)

    df_prj = (
        df_prj
        .merge(count_scans(last_month, "Last Month"), on="Project Name", how="left")
        .merge(count_scans(this_month, "This Month"), on="Project Name", how="left")
        .merge(count_scans(last_week, "Last Week"), on="Project Name", how="left")
        .merge(count_scans(this_week, "This Week"), on="Project Name", how="left")
        .merge(count_scans(yesterday, "Yesterday"), on="Project Name", how="left")
        .merge(count_scans(today, "Today"), on="Project Name", how="left")
        .fillna(0)
    )

    return df_prj[
        ["Project Name","Last Month", "This Month", "Last Week", "This Week", "Yesterday", "Today"]
    ].sort_values(by="Last Month", ascending=False)

def get_id_list_from_file():
    all_lights_list = df_light.apply(lambda row: int(row['lig_id']), axis=1).tolist()
    all_ids = [id_ for id_ in all_lights_list]
    return all_ids

def get_coordinates_list_from_server():
    data = fetch_data_from_server('api/v1/coordinate_systems', token_key="_lig_token").get('coordinate_systems',[])    
    return [f"{item['id']}-{item['name']}" for item in data]

#å„²å­˜ project_rank è³‡æ–™çš„å‡½æ•¸
def save_project_rank():
    if 'project_rank_data' in st.session_state:
        # ç¢ºä¿è³‡æ–™å¤¾å­˜åœ¨
        output_dir = "data"
        os.makedirs(output_dir, exist_ok=True)
        
        # ç”¢ç”Ÿæª”æ¡ˆåç¨±ï¼Œä½¿ç”¨ç•¶å‰æ—¥æœŸæ™‚é–“
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"project_rank_{timestamp}.csv"
        filepath = os.path.join(output_dir, filename)
        try:
            st.session_state.project_rank.to_csv(filepath, index=False)
            logger.info(f"Project rank saved to {filepath}")
        except Exception as e:
            logger.error(f"Failed to save project rank: {e}")
        
    else:
        logger.warning("No project_rank_data found in session state")

# =======================
# 6. Figure è£½åœ–
# =======================

def plot_heatmpy(df):    
    # ã€ä¿®æ”¹è™•ï¼šæ·»åŠ CSSæ¨£å¼ä¾†ç¦ç”¨åœ°åœ–äº¤äº’ã€‘
    st.markdown("""
    <style>
    .stDeckGlJsonChart > div {
        pointer-events: none !important;
        height: 350px !important;  /* è¨­å®šåœ°åœ–é«˜åº¦ */
    }
    .stDeckGlJsonChart canvas {
        pointer-events: none !important;
        height: 350px !important;  /* è¨­å®šcanvasé«˜åº¦ */
    }
    .stDeckGlJsonChart {
        height: 350px !important;  /* è¨­å®šæ•´å€‹å®¹å™¨é«˜åº¦ */
    }
    </style>
    """, unsafe_allow_html=True)

    # å®šç¾©ç†±åŠ›åœ–å±¤
    layer = pdk.Layer(
        "HeatmapLayer",  # ä½¿ç”¨ç†±åŠ›åœ–å±¤
        df,  # æ•¸æ“šæº df_scan_lat_long_datefilter_zvalue_merged
        get_position=["prj_lon", "prj_lat"],  # æŒ‡å®šç¶“ç·¯åº¦åˆ—
        get_weight="Scan_Count",  # æŒ‡å®šç†±åŠ›åœ–çš„æ¬Šé‡åˆ—
        radius_pixels=50,  # è¨­ç½®ç†±é»çš„åŠå¾‘
        colorRange=[  # è‡ªå®šç¾©é¡è‰²ç¯„åœ
            [33, 102, 172],  # ä½å¼·åº¦é¡è‰²
            [103, 169, 207],  # ...
            [209, 229, 240],  # ...
            [253, 219, 199],  # ...
            [239, 138, 98],  # ...
            [178, 24, 43],  # é«˜å¼·åº¦é¡è‰²
        ],
        opacity=0.6,  # è¨­ç½®ä¸é€æ˜åº¦
    )
    # è¨­ç½®åœ°åœ–åˆå§‹è¦–åœ–ä½ç½®
    view_state = pdk.ViewState(
        latitude=31.65627693618275, 
        longitude=107.65665580285913, 
        zoom=1.5
    )

    # ä½¿ç”¨pydeckæ¸²æŸ“åœ°åœ–
    st.pydeck_chart(
        pdk.Deck(
            layers=[layer],
            initial_view_state=view_state,
            # å•Ÿç”¨åœ°åœ–æ§ä»¶
            map_style="mapbox://styles/mapbox/light-v9",
        ),
        use_container_width=True,  # ä½¿ç”¨å®¹å™¨å¯¬åº¦
    )

def display_metric(title, value, height="100px"):
    formatted_value = f"{value:,}"
    st.markdown(f"""
        <style>
            .custom-metric {{
                display: flex;
                flex-direction: row;
                justify-content: center;
                align-items: center;
                background-color: #f0f2f6;
                border-radius: 8px;
                padding: 10px 20px;
                height: {height};
                box-shadow: 0 2px 4px rgba(0,0,0,0.1);
                gap: 12px;  /* å…ƒç´ é–“è· */
            }}
            .custom-metric h1 {{
                margin: 0;
                font-size: 28px;
                color: #333;
            }}
            .custom-metric p1 {{
                margin: 0;
                font-size: 16px;
                color: #666;
            }}
        </style>
        <div class="custom-metric">
            <p1>{title}</p1>
            <h1>{formatted_value}</h1>   
        </div>
    """, unsafe_allow_html=True)

@st.cache_data
def plot_stacked_histogram_with_dual_y_axis(data, start_date, end_date,timecol, col_name, multiplier):
    data['time_normalized'] = data[timecol].dt.normalize()  # è½‰æˆ 00:00 çš„ Timestamp
    date_index = pd.date_range(start_date, end_date, tz='Asia/Taipei')
    size_result = data.groupby(['time_normalized', col_name]).size()
    daily_counts = (size_result * multiplier).unstack(fill_value=0).reindex(date_index, fill_value=0)
    # è¨ˆç®—ç´¯è¨ˆ count
    daily_counts['cumulative'] = daily_counts.sum(axis=1).cumsum()

    # daily_counts = daily_counts.reset_index().rename(columns={'index': 'date'})
    dates = daily_counts.index
    ticktext = [
        f"<b style='color:red;'>{date.strftime('%b %d')}</b>" if date.weekday() >= 5 else date.strftime('%b %d')
        for date in dates
    ]
    tickvals = dates

    # ä½¿ç”¨ Plotly Express çš„é è¨­é¡è‰²åºåˆ—
    color_sequence = px.colors.qualitative.Plotly

    # å‰µå»ºåœ–è¡¨
    fig = go.Figure()

    # æ·»åŠ å †ç–Šç›´æ–¹åœ–ï¼Œæ¯å€‹ trace æ˜ç¢ºæŒ‡å®šé¡è‰²
    for i, col_name in enumerate(daily_counts.columns[:-1]):  # å¿½ç•¥ 'cumulative'
        fig.add_trace(
            go.Bar(
                x=daily_counts.index,
                y=daily_counts[col_name],
                name=f"{col_name}",
                marker=dict(color=color_sequence[i % len(color_sequence)]),
                hovertemplate=f'{col_name}: ' + "%{y}<extra></extra>"
            )
        )

    # # æ·»åŠ ç´¯è¨ˆæŠ˜ç·šåœ–
    fig.add_trace(
        go.Scatter(
            x=daily_counts.index,
            y=daily_counts['cumulative'],
            name="Cumulative Count",
            mode="lines+markers",
            line=dict(color="red"),
            hovertemplate="Date: %{x}<br>Cumulative: %{y}<extra></extra>",
            yaxis='y2',
        )
    )

    # è¨­ç½®é›™ Y è»¸
    fig.update_layout(
        # title="Interactive Stacked Histogram with Dual Y-Axis",
        xaxis=dict(
            title="Date",
            tickvals=tickvals,  # ç¢ºä¿æ¯ä¸€å¤©éƒ½æœ‰å­—
            ticktext=ticktext,  # è‡ªå®šç¾©æ–‡å­—ï¼Œé€±æœ«é¡¯ç¤ºç‚ºç´…è‰²
            tickangle=45,  # æ—‹è½‰ X è»¸æ¨™ç±¤
        ),
        yaxis=dict(
            title="Daily Counts",
            range=[0, daily_counts.iloc[:, :-1].values.max() * 1.2],  # Y1ç¯„åœå¾0é–‹å§‹
            showgrid=True,  # ä¸» Y è»¸é¡¯ç¤º Grid
        ),
        yaxis2=dict(
            title="Cumulative Count",
            overlaying="y",  # èˆ‡ä¸» Y è»¸é‡ç–Š
            side="right",
            range=[0, daily_counts['cumulative'].max() * 1.2],  # Y2ç¯„åœå¾0é–‹å§‹
            showgrid=False  # ç¦ç”¨æ¬¡ Y è»¸çš„ Grid
        ),
        barmode="stack",  # å †ç–Šæ¨¡å¼
        legend=dict(title="Legend", orientation="h", x=0.5, xanchor="center", y=-0.2),
        hovermode="x unified"  # çµ±ä¸€ hover
    )
    daily_counts_csv = daily_counts.reset_index().rename(columns={'index': 'date'})
    daily_counts_csv['date'] = daily_counts_csv['date'].dt.strftime('%Y-%m-%d')
    return daily_counts_csv, fig

def week_pie_fig(df):
    weekday_counts = df['weekday'].value_counts().sort_index()
    weekday_names = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']
    weekday_counts = weekday_counts.reindex(range(7), fill_value=0)
    weekday_counts.index = [weekday_names[i] for i in weekday_counts.index]
    total_scans = weekday_counts.sum()
    weekday_proportions = (weekday_counts / total_scans * 100).round(2)  # è½‰æ›ç‚ºç™¾åˆ†æ¯”ï¼Œå››æ¨äº”å…¥åˆ°å°æ•¸é»å¾Œå…©ä½
    week_pie_fig = go.Figure(data=[go.Pie(
        labels=weekday_proportions.index,
        values=weekday_proportions.values,
        hole=0.3,  # è¨­ç½®ä¸­ç©ºåœ“å½¢ï¼ˆç”œç”œåœˆåœ–ï¼‰
        textinfo='label+percent',  # é¡¯ç¤ºæ¨™ç±¤å’Œç™¾åˆ†æ¯”
        textposition='auto',  # æ–‡å­—ä½ç½®è‡ªå‹•èª¿æ•´
        hoverinfo='label+percent+value',  # æ‡¸åœé¡¯ç¤ºæ¨™ç±¤ã€ç™¾åˆ†æ¯”å’Œæ•¸å€¼
        marker=dict(colors=px.colors.qualitative.Plotly)  # ä½¿ç”¨ Plotly çš„é è¨­é¡è‰²
    )])

    week_pie_fig.update_layout(
        title={
            "text": "Weekly Scan",
            "x": 0.5,
            "xanchor": "center"
        }
    )
    return week_pie_fig

def time_distribution(df,start_date,end_date):
    # å–å¾—æƒææ—¥æœŸ (å°‡æ™‚é–“éƒ¨åˆ†æ­¸é›¶)
    df["scan_date"] = df["scantime"].dt.normalize()

    # å–å¾—æƒææ™‚é–“éƒ¨åˆ†ï¼šåªå–æ™‚é–“ï¼Œä¸¦è½‰æ›æˆå›ºå®šæ—¥æœŸï¼ˆé è¨­ç‚º 1900-01-01ï¼‰çš„ datetime ç‰©ä»¶
    # df["scan_time_only"] = pd.to_datetime(df["scantime"].dt.strftime('%H:%M:%S'))
    # ä¿®æ­£ scan_time_onlyï¼šåªæå–æ™‚é–“éƒ¨åˆ†ï¼Œè½‰ç‚ºä¸€å¤©ä¸­çš„ç§’æ•¸æˆ– datetime.time
    df["scan_time_only"] = df["scantime"].dt.time  # æå–æ™‚é–“éƒ¨åˆ† (datetime.time å°è±¡)

    # ç‚ºäº† Plotly çš„ Y è»¸ï¼ˆéœ€è¦æ•¸å€¼ï¼‰ï¼Œå°‡æ™‚é–“è½‰æ›ç‚ºä¸€å¤©ä¸­çš„ç§’æ•¸
    df["scan_time_seconds"] = df["scantime"].dt.hour * 3600 + \
                             df["scantime"].dt.minute * 60 + \
                             df["scantime"].dt.second

    # å°‡ç§’æ•¸è½‰æ›ç‚º HH:MM:SS æ ¼å¼ï¼ˆå­—ä¸²ï¼‰
    df["scan_time_str"] = df["scan_time_seconds"].apply(lambda x: f"{x//3600:02}:{(x%3600)//60:02}:{x%60:02}")

    date_index = pd.date_range(start_date, end_date, tz='Asia/Taipei', freq='D')
    ticktext = [
    f"<b style='color:red;'>{date.strftime('%b %d')}</b>" if date.weekday() >= 5 else date.strftime('%b %d')
    for date in date_index
    ]
    tickvals = date_index 

    # ç¹ªè£½æ•£é»åœ–ï¼šx è»¸ç”¨æƒææ—¥æœŸï¼Œy è»¸ç”¨ç•¶å¤©æƒææ™‚é–“
    fig_time_distribution = go.Figure(data=go.Scatter(
        x=df["scan_date"],
        y=df["scan_time_seconds"],
        mode='markers',
        marker=dict(color='green', opacity=0.6),
        customdata=df["scan_time_str"],
        hovertemplate="Date: %{x}<br>Time: %{customdata}<extra></extra>"
    ))
    # è¨ˆç®—æ•´å€‹æœŸé–“çš„æœ€é«˜å€¼å’Œæœ€ä½å€¼ï¼ˆåŸºæ–¼ç§’æ•¸ï¼‰
    overall_max_seconds = df["scan_time_seconds"].max()
    overall_min_seconds = df["scan_time_seconds"].min()

    # æ·»åŠ æœ€é«˜å€¼çš„æ°´å¹³ç·š
    fig_time_distribution.add_hline(
        y=overall_max_seconds,
        line_width=3,
        line_color="red",
        opacity=0.8,
        layer="below",
        annotation_text="Max Time",
        annotation_position="right",
        annotation_font=dict(color="red")
    )

    # æ·»åŠ æœ€ä½å€¼çš„æ°´å¹³ç·š
    fig_time_distribution.add_hline(
        y=overall_min_seconds,
        line_width=3,
        line_color="blue",
        opacity=0.8,
        layer="below",
        annotation_text="Min Time",
        annotation_position="right",
        annotation_font=dict(color="blue")
    )
    # å®šç¾© Y è»¸æ¯å…©å°æ™‚çš„åˆ»åº¦
    y_tickvals = list(range(0, 24*3600 + 1, 2*3600))  # å¾ 0 åˆ° 24 å°æ™‚ï¼Œæ¯ 2 å°æ™‚
    y_ticktext = [f"{hour:02d}:00" for hour in range(0, 25, 2)]

    # æ›´æ–°ä½ˆå±€
    fig_time_distribution.update_layout(
        xaxis=dict(
            title="Scan Date",
            type="date",
            range=[start_date - pd.Timedelta(days=2), end_date + pd.Timedelta(days=1)],
            tickmode="array",
            tickvals=tickvals,
            ticktext=ticktext,
            tickangle=45,
            tickformat="%b-%d",
            showgrid=True,
            gridcolor="lightgray"
        ),
        yaxis=dict(
            title="Scan Time",
            tickvals=y_tickvals,
            ticktext=y_ticktext,
            range=[0, 24*3600],
            showgrid=True,
            gridcolor="lightgray"
        ),
        height=500
    )
    return fig_time_distribution

def h24_distribution(df,col_name):
    # è¨ˆç®—æ¯ 6 å°æ™‚å€é–“çš„æƒææ¬¡æ•¸åˆ†ä½ˆ
    df['hour'] = df[col_name].dt.hour  # æå–å°æ™‚ï¼ˆ0-23ï¼‰

    # å°‡å°æ™‚åˆ†ç‚º 4 å€‹ 6 å°æ™‚å€é–“
    def categorize_hour(hour):
        if 1 <= hour <= 6:
            return "1-6 AM"
        elif 7 <= hour <= 12:
            return "7-12 AM"
        elif 13 <= hour <= 18:
            return "1-6 PM"
        else:  # 19 <= hour <= 24
            return "7-12 PM"

    df['hour_interval'] = df['hour'].apply(categorize_hour)
    hour_interval_counts = df['hour_interval'].value_counts()

    # å®šç¾©æ™‚é–“æ®µåç¨±ï¼ˆç¢ºä¿æ‰€æœ‰å€é–“éƒ½åŒ…å«ï¼‰
    hour_intervals = ['1-6 AM', '7-12 AM', '1-6 PM', '7-12 PM']
    
    # ç¢ºä¿æ‰€æœ‰æ™‚é–“æ®µéƒ½æœ‰æ•¸æ“šï¼ˆå¡«è£œç¼ºå¤±çš„æ™‚é–“æ®µç‚º 0ï¼‰
    hour_interval_counts = hour_interval_counts.reindex(hour_intervals, fill_value=0)

    # è¨ˆç®—ç¸½æƒææ¬¡æ•¸
    total_scans = hour_interval_counts.sum()
    
    # è¨ˆç®—æ¯å€‹æ™‚é–“æ®µçš„æ¯”ä¾‹
    hour_interval_proportions = (hour_interval_counts / total_scans * 100).round(2)  # è½‰æ›ç‚ºç™¾åˆ†æ¯”ï¼Œå››æ¨äº”å…¥åˆ°å°æ•¸é»å¾Œå…©ä½

    # å‰µå»ºæ™‚é–“å€é–“åˆ†ä½ˆåœ“å½¢åœ–
    fig_h24_distribution = go.Figure(data=[go.Pie(
        labels=hour_interval_proportions.index,
        values=hour_interval_proportions.values,
        hole=0.3,  # è¨­ç½®ä¸­ç©ºåœ“å½¢ï¼ˆç”œç”œåœˆåœ–ï¼‰
        textinfo='label+percent',  # é¡¯ç¤ºæ¨™ç±¤å’Œç™¾åˆ†æ¯”
        textposition='auto',  # æ–‡å­—ä½ç½®è‡ªå‹•èª¿æ•´
        hoverinfo='label+percent+value',  # æ‡¸åœé¡¯ç¤ºæ¨™ç±¤ã€ç™¾åˆ†æ¯”å’Œæ•¸å€¼
        marker=dict(colors=px.colors.qualitative.Plotly)  # ä½¿ç”¨ Plotly çš„é è¨­é¡è‰²
    )])

    fig_h24_distribution.update_layout(
        title={
            "text": f"Hourly Scan Distribution",
            "x": 0.5,
            "xanchor": "center"
        }
    )
    return fig_h24_distribution

def clickobjdist(df,multiplier):
    objclick_size_result = df.groupby(['ar_obj','location_x','location_z']).size().reset_index(name='click_count')
    ranking = objclick_size_result.copy()
    ranking['click_count'] = (ranking['click_count'] * multiplier).astype(int)
    ranking = ranking.sort_values('click_count', ascending=False)
    ranking_top20 = ranking.head(20)
    # å‹•æ…‹è¨ˆç®—æ°£æ³¡å¤§å°ç¸®æ”¾å› å­
    min_size = 5   # æœ€å°æ°£æ³¡å¤§å°ï¼ˆå¯èª¿æ•´ï¼‰
    max_size = 50  # æœ€å¤§æ°£æ³¡å¤§å°ï¼ˆå¯èª¿æ•´ï¼‰
    click_min = ranking_top20["click_count"].min()  # click_count æœ€å°å€¼
    click_max = ranking_top20["click_count"].max()  # click_count æœ€å¤§å€¼

    # å¦‚æœ click_max == click_minï¼Œé¿å…é™¤ä»¥é›¶
    if click_max == click_min:
        scale_factor = 0.5  # è‹¥æ‰€æœ‰å€¼ç›¸åŒï¼Œä½¿ç”¨å›ºå®šç¸®æ”¾
    else:
        # è¨ˆç®—ç¸®æ”¾å› å­ï¼Œä½¿ click_count æ˜ å°„åˆ° [min_size, max_size]
        scale_factor = (max_size - min_size) / (click_max - click_min)
    # è¨ˆç®—æ°£æ³¡å¤§å°
    bubble_sizes = min_size + (ranking_top20["click_count"] - click_min) * scale_factor

    # ç¹ªè£½æ³¡æ³¡åœ–
    fig_ranking = go.Figure()

    fig_ranking.add_trace(
        go.Scatter(
            x=ranking_top20["location_x"],
            y=ranking_top20["location_z"],
            mode='markers',  # åªé¡¯ç¤ºæ°£æ³¡
            marker=dict(
                size=bubble_sizes,  # æ°£æ³¡å¤§å°èˆ‡é»æ“Šæ¬¡æ•¸æˆæ­£æ¯”ï¼ˆèª¿æ•´å€æ•¸ 0.5ï¼‰
                color=ranking_top20["click_count"],      # æ ¹æ“šé»æ“Šæ¬¡æ•¸è‘—è‰²
                colorscale='blues',                    # ä½¿ç”¨æ©™è‰²æ¼¸è®Šï¼ˆèˆ‡åŸ Bar çš„ orange ä¸€è‡´ï¼‰
                opacity=0.85,
                showscale=True,                          # é¡¯ç¤ºé¡è‰²æ¢
                line=dict(width=0.1, color='black')        # æ°£æ³¡é‚Šæ¡†
            ),
            text=ranking_top20.apply(lambda row: f"ç‰©ä»¶: {row['ar_obj']}<br>é»æ“Šæ¬¡æ•¸: {row['click_count']}", axis=1),
            hovertemplate='%{text}'  # æ‡¸åœæ™‚é¡¯ç¤ºç‰©ä»¶åç¨±å’Œé»æ“Šæ¬¡æ•¸
        )
    )
    # æ›´æ–°ä½ˆå±€
    fig_ranking.update_layout(
        xaxis_title="Location X(m)",
        yaxis_title="Location Y(m)",
        xaxis=dict(
            range=[-10, 10],  # å›ºå®š X è»¸ç¯„åœ
            dtick = 1,
            tickangle=45,      # å‚¾æ–œ X è»¸æ¨™ç±¤ï¼Œé¿å…é‡ç–Š
            showgrid=True,
            gridcolor='lightgray',
            gridwidth = 1,
            zeroline=True,    # é¡¯ç¤º x=0 ç·š
            zerolinecolor='black',  # x=0 ç·šé¡è‰²
            zerolinewidth=3
        ),
        yaxis=dict(
            range=[10, -10],   # å›ºå®š Y è»¸ç¯„åœ
            dtick = 1,
            scaleanchor="x",
            scaleratio=1,      # ä¿è­‰ X å’Œ Y è»¸æ¯”ä¾‹ 1:1
            showgrid=True,    # é¡¯ç¤ºç¶²æ ¼ç·š
            gridcolor='lightgray',
            gridwidth=1,
            zeroline=True,    # é¡¯ç¤º x=0 ç·š
            zerolinecolor='black',  # x=0 ç·šé¡è‰²
            zerolinewidth=3
        ),
        width=600,
        height =600,
        autosize = False,
        template="plotly_white",   # ä½¿ç”¨ç™½è‰²ä¸»é¡Œ
        showlegend=False           # ç„¡éœ€åœ–ä¾‹
    )
    return fig_ranking,ranking

def plot_user_experience_bar(experience_df, selected_scene):
    df = experience_df[experience_df['scene'] == selected_scene]
    df['label'] = df['user_id'].astype(str)
    fig = go.Figure(data=[
        go.Bar(
            x=df['label'],
            y=df['duration_sec'],
            text=df['duration_sec'],
            textposition='outside',
            marker_color='lightblue'
        )
    ])
    fig.update_layout(
        title=f"{selected_scene} ä½¿ç”¨è€…æ¯æ®µé«”é©—æ™‚é–“ï¼ˆç§’ï¼‰",
        xaxis_title="ä½¿ç”¨è€…/æ—¥æœŸ/æ®µè½",
        yaxis_title="é«”é©—æ™‚é–“ï¼ˆç§’ï¼‰",
        xaxis_tickangle=45,
        height=500,
        template="plotly_white"
    )
    return fig

def plot_experience_box(experience_df, selected_scene):
    df = experience_df[experience_df['scene'] == selected_scene]
    fig = px.box(
        df,
        y="duration_sec",
        points="all",  # é¡¯ç¤ºæ‰€æœ‰æ•¸æ“šé»
        title=f"{selected_scene} é«”é©—æ™‚é–“åˆ†å¸ƒ",
        labels={"duration_sec": "é«”é©—æ™‚é–“ï¼ˆç§’ï¼‰"},
        template="plotly_white"
    )
    return fig

# =======================
# 7. Table è£½è¡¨
# =======================

def AgGridTable(df):
    # é…ç½®è¡¨æ ¼é¸é …
    gb = GridOptionsBuilder.from_dataframe(df)
    gb.configure_selection(selection_mode="single", use_checkbox=False)  # å–®é¸æ¨¡å¼ï¼Œä½¿ç”¨å‹¾é¸æ¡†
    gb.configure_grid_options(domLayout="normal")  # è¨­ç½®è¡¨æ ¼å¸ƒå±€
    gb.configure_pagination(paginationAutoPageSize=True, paginationPageSize=8)  # å¯é¸ï¼Œæ·»åŠ åˆ†é åŠŸèƒ½
    grid_options = gb.build()
    # æ¸²æŸ“ Ag-Grid
    response = AgGrid(
        df,
        gridOptions=grid_options,
        update_mode=GridUpdateMode.SELECTION_CHANGED,  # ç›£æ§é¸æ“‡è®ŠåŒ–
        fit_columns_on_grid_load=True,
        theme="streamlit",
        height=400,
        width = '100%',
        use_container_width=True,
        enable_enterprise_modules=False,
    )
    return response
    
# =======================
# 8. Fuction åŠŸèƒ½
# =======================
def download_csv_button(df, filename, label):
    csv_buffer = df.to_csv(index=False, encoding='utf-8-sig')
    st.download_button(
        label=label,
        data=csv_buffer,
        file_name=filename,
        mime="text/csv",
        key=f"download_{filename}"
    )

def split_project_name(df): # æ‹†åˆ†åœ°å€ã€å®¢æˆ¶åã€æ´»å‹•åçš„å‡½å¼
    # æ‹†åˆ†æˆåœ°å€ã€å®¢æˆ¶åã€æ´»å‹•å
    df[['region', 'client', 'campaign']] = df['Project Name'].str.split('-', expand=True)
    return df

def extract_coordinate_name(row):
    try:
        # å…ˆå°‡ coordinate_system_id è½‰æˆå­—ä¸²ä¸¦å»é™¤ç©ºç™½
        coordinate_id = str(row['coordinate_system_id']).strip()
        # å°‡ Coordinates å…ˆ stripï¼Œå†ç”¨ literal_eval
        coordinates_str = row['Coordinates'].strip()

        coordinates = ast.literal_eval(coordinates_str)  # å°‡å­—ä¸²è½‰ç‚ºåˆ—è¡¨

        # éæ­· Coordinatesï¼Œæ‰¾åˆ°å°æ‡‰çš„åç¨±
        for coord in coordinates:
            if coord.strip().startswith(coordinate_id + "-"):
                return coord.split("-", 1)[1].strip()  # è¿”å› ID ä¹‹å¾Œçš„åç¨±éƒ¨åˆ†
    except (ValueError, SyntaxError, KeyError, TypeError):
        return None  # å¦‚æœè§£æå¤±æ•—æˆ–æ ¼å¼éŒ¯èª¤ï¼Œè¿”å› None
    return None

def calculate_scan_count(df, start_date, end_date):
    # è½‰æ› scantime ä¸¦è™•ç†æ™‚å€
    df['scantime'] = pd.to_datetime(df['scantime'], errors="coerce")
    invalid_times = df['scantime'].isna().sum()
    if invalid_times > 0:
        st.warning(f"âš ï¸ ç™¼ç¾ {invalid_times} ç­†ç„¡æ•ˆçš„ scantime æ•¸æ“šï¼Œå·²å¿½ç•¥é€™äº›è¨˜éŒ„ã€‚")
    if invalid_times == len(df):
        st.error("ğŸš¨ æ‰€æœ‰ scantime æ•¸æ“šå‡ç„¡æ•ˆï¼Œç„¡æ³•è¨ˆç®—æƒæé‡ï¼")
        return 0
    if df['scantime'].dt.tz is None:  # è‹¥ç„¡æ™‚å€ï¼Œè¨­å®šå°åŒ—æ™‚å€
        df['scantime'] = df['scantime'].dt.tz_localize("Asia/Taipei")
    else:  # è‹¥å·²æœ‰æ™‚å€ï¼Œè½‰æ›åˆ°å°åŒ—æ™‚å€
        df['scantime'] = df['scantime'].dt.tz_convert("Asia/Taipei")
    
    # å°‡ scantime normalize (åªä¿ç•™æ—¥æœŸ)
    df['scantime_normalized'] = df['scantime'].dt.normalize()
    
    # ç¢ºä¿ start_date å’Œ end_date ä¹Ÿ normalize
    start_date = pd.Timestamp(start_date).replace(hour=0, minute=0).tz_localize("Asia/Taipei")
    end_date = pd.Timestamp(end_date).replace(hour=23, minute=59).tz_localize("Asia/Taipei")
            
    # éæ¿¾æ•¸æ“š
    mask = (df['scantime_normalized'] >= start_date) & (df['scantime_normalized'] <= end_date)
    return df[mask].shape[0]

def ensure_date_format(value, timezone="Asia/Taipei"):
    # ç¢ºä¿å‚³å…¥å€¼è½‰ç‚º pandas.Timestamp ä¸¦è¨­ç½®æ™‚å€
    if not isinstance(value, pd.Timestamp):
        value = pd.to_datetime(value, errors="coerce")
    if timezone:  # å¦‚æœæŒ‡å®šäº†æ™‚å€ï¼Œè½‰æ›åˆ°è©²æ™‚å€
        if value.tzinfo is None:
            value = value.tz_localize(timezone)
        else:
            value = value.tz_convert(timezone)
    return value

def df_date_filter(df, col_name, start_day, end_day):
    df[col_name] = pd.to_datetime(df[col_name], errors="coerce").apply(lambda x: ensure_date_format(x))
    df['scantime_normalized'] = df[col_name].dt.normalize()
    start_day = ensure_date_format(start_day)
    end_day = ensure_date_format(end_day)
    start_day = pd.Timestamp(start_day).replace(hour=0, minute=0)
    end_day = pd.Timestamp(end_day).replace(hour=23, minute=59)
    
    return df[(df['scantime_normalized'] >= start_day) & (df['scantime_normalized'] <= end_day)]

def load_data(filepath):
    try:
        with open(filepath, 'r', encoding='utf-8-sig') as f:
            content = f.read()
        df = pd.read_csv(filepath,encoding="utf-8-sig",dtype={'Owner Email': str})
        df['Start Date'] = pd.to_datetime(df['Start Date'], format='%Y-%m-%d', errors='coerce')
        df['End Date'] = pd.to_datetime(df['End Date'], format='%Y-%m-%d', errors='coerce')
        # if 'Owner Email' not in df.columns:
        #     df['Owner Email'] = '[]'
        def safe_parse_json(x):
            if pd.notna(x):
                if isinstance(x, str):
                    try:
                        parsed = json.loads(x)
                        if isinstance(parsed, list):
                            return parsed
                        return [parsed] if parsed else []
                    except json.JSONDecodeError:
                        return [x]  # å¦‚æœä¸æ˜¯ JSONï¼Œä½œç‚ºå–®ä¸€å­—ä¸²è™•ç†
                elif isinstance(x, list):
                    return x
            return []
        df['Owner Email'] = df['Owner Email'].apply(safe_parse_json)
        return df
    except FileNotFoundError:
        st.error(f"File not found: {filepath}")
        cols = ['ProjectID', 'Project Name', 'Start Date', 'End Date', 'Coordinates', 'Light ID', 'Scenes', 'Is Active', 'Latitude and Longitude', 'Owner Email']
        return pd.DataFrame(columns=cols)
    except Exception as e:
        st.error(f"Error loading file {filepath}: {e}")
        cols = ['ProjectID', 'Project Name', 'Start Date', 'End Date', 'Coordinates', 'Light ID', 'Scenes', 'Is Active', 'Latitude and Longitude', 'Owner Email']
        return pd.DataFrame(columns=cols)

def check_dataframe(df, name, required_columns):
    if df is None or df.empty:
        st.error(f"ğŸš¨ {name} æ•¸æ“šç‚ºç©ºï¼Œè«‹æª¢æŸ¥æ•¸æ“šä¾†æºï¼")
        st.stop()
    missing_cols = [col for col in required_columns if col not in df.columns]
    if missing_cols:
        st.error(f"ğŸš¨ {name} ç¼ºå°‘å¿…è¦æ¬„ä½ï¼š{', '.join(missing_cols)}")
        st.stop()

def get_data_hash(df):
    return hashlib.md5(df.to_string().encode()).hexdigest()

# æ’ç¨‹ä»»å‹™
def schedule_tasks():
    # æ¯å¤©æ—©ä¸Š 6:00 å„²å­˜
    schedule.every().day.at("08:17").do(save_project_rank)
    logger.info("Scheduled tasks set for 08:05 daily")
    # æ¯å¤©ä¸‹åˆ 5:00 å„²å­˜
    schedule.every().day.at("17:00").do(save_project_rank)

# åœ¨èƒŒæ™¯åŸ·è¡Œæ’ç¨‹çš„å‡½æ•¸
def run_scheduler():
    while True:
        schedule.run_pending()
        time.sleep(60)  # æ¯åˆ†é˜æª¢æŸ¥ä¸€æ¬¡
        logger.debug("Scheduler checked pending tasks")

def compute_multi_experiences(df_click_obj, gap_threshold_sec=600):
    df = df_click_obj.copy()
    df['clicktime'] = pd.to_datetime(df['clicktime'])
    df['click_date'] = df['clicktime'].dt.date

    df = df.sort_values(by=['user_id', 'scene', 'click_date', 'clicktime'])
    df['prev_time'] = df.groupby(['user_id', 'scene', 'click_date'])['clicktime'].shift()
    df['delta_sec'] = (df['clicktime'] - df['prev_time']).dt.total_seconds().fillna(0)

    df['new_experience_flag'] = df['delta_sec'] > gap_threshold_sec
    df['experience_id'] = df.groupby(['user_id', 'scene', 'click_date'])['new_experience_flag'].cumsum()

    grouped = df.groupby(['user_id', 'scene', 'click_date', 'experience_id'])
    experience_df = grouped.agg(
        start_time=('clicktime', 'min'),
        end_time=('clicktime', 'max')
    ).reset_index()

    experience_df['duration_sec'] = (experience_df['end_time'] - experience_df['start_time']).dt.total_seconds()

    return experience_df

# =======================
# 9. å®šç¾©æ—¥æœŸå€æ®µåŠè¨ˆç®—å€æ®µæƒæé‡
# =======================
# è¨ˆç®—å„æ™‚é–“ç¯„åœçš„æƒæé‡
today_scan = calculate_scan_count(df_scan, today, today)
yesterday_scan = calculate_scan_count(df_scan, yesterday, yesterday)
this_week_scan = calculate_scan_count(df_scan, start_of_week, today)
last_week_scan = calculate_scan_count(df_scan, start_of_last_week, end_of_last_week)
this_month_scan = calculate_scan_count(df_scan, start_of_month, today)
last_month_scan = calculate_scan_count(df_scan, start_of_last_month, end_of_last_month)  
default_start_date = datetime.date(last_scan_time) - timedelta(days=30)

# éæ¿¾è¿‘ä¸€å¹´è³‡æ–™
today_timestamp = pd.Timestamp.today()
one_year_ago = pd.Timestamp.now(tz='Asia/Taipei') - pd.DateOffset(months=12)
df_recent = df_scan[df_scan['scantime'] >= one_year_ago]

# è¨ˆç®—æ¯æœˆæƒæé‡
df_recent['month'] = df_recent['scantime'].dt.to_period('M').astype(str)
monthly_scan_data = df_recent.groupby('month').size().reset_index(name='Scan Count')
# è¨ˆç®— y è»¸æœ€å¤§å€¼
max_scan = monthly_scan_data['Scan Count'].max()
# ç•«åœ–
fig_monthly_scan = px.bar(
    monthly_scan_data,
    x='month',
    y='Scan Count',
    text='Scan Count',
    title='ğŸ“Š Monthly Scan Count (Last 12 Months)',
    labels={'month': 'æœˆä»½', 'Scan Count': 'æƒææ¬¡æ•¸'},
    height=400
)
fig_monthly_scan.update_traces(textposition='outside')
# âœ… é¡¯ç¤ºæ‰€æœ‰æœˆä»½ + Y è»¸è¨­ç‚ºæœ€å¤§å€¼çš„ 1.2 å€
fig_monthly_scan.update_layout(
    xaxis_tickangle=-45,
    xaxis=dict(type='category'),  # ä¸çœç•¥é¡åˆ¥æ¨™ç±¤
    yaxis=dict(range=[0, max_scan * 1.2]),  # Y è»¸ç¯„åœæ‰‹å‹•èª¿æ•´
    bargap=0.6 
)

# =======================
# 10. é é¢ç¯„ä¾‹ï¼šAll Projects é é¢ (ã€ä¿®æ”¹è™•ï¼šç°¡åŒ–é é¢é‚è¼¯ï¼Œåˆ†é›¢å„å€å¡Šã€‘)
# =======================
def all_projects():    
    user_email = st.session_state.get("logged_in_user", "")

    filter_result = st.session_state.df_project['Owner Email'].apply(lambda owners: user_email in owners)
    filtered_df_project = st.session_state.df_project[filter_result]

    scan_hash = get_data_hash(df_scan)
    project_hash = get_data_hash(filtered_df_project)

        # æª¢æŸ¥æ˜¯å¦éœ€è¦é‡æ–°è¨ˆç®— merge_data å’Œ project_rank
    if ('merge_data_yesterday' not in st.session_state or
        'merge_data_today' not in st.session_state or
        'merge_data_lastweek' not in st.session_state or
        'merge_data_thisweek' not in st.session_state or
        'merge_data_lastmonth' not in st.session_state or
        'merge_data_thismonth' not in st.session_state or
        'project_rank_card' not in st.session_state ):
        
        st.session_state.merge_data_yesterday = prepare_project_data(filtered_df_project, df_scan, yesterday, yesterday)
        st.session_state.merge_data_today = prepare_project_data(filtered_df_project, df_scan, today, today)
        st.session_state.merge_data_lastweek = prepare_project_data(filtered_df_project, df_scan, start_of_last_week, end_of_last_week)
        st.session_state.merge_data_thisweek = prepare_project_data(filtered_df_project, df_scan, start_of_week, today)
        st.session_state.merge_data_lastmonth = prepare_project_data(filtered_df_project, df_scan, start_of_last_month, end_of_last_month)
        st.session_state.merge_data_thismonth = prepare_project_data(filtered_df_project, df_scan, start_of_month, today)
        st.session_state.project_rank_card = generate_project_rank_card(filtered_df_project,st.session_state.merge_data_lastmonth, st.session_state.merge_data_thismonth,st.session_state.merge_data_lastweek, st.session_state.merge_data_thisweek,st.session_state.merge_data_yesterday, st.session_state.merge_data_today)
    
    # =======================
    # 7-3. ç†±åŠ›åœ–ã€æ’è¡Œæ¦œã€çµ±è¨ˆæ•¸æ“š
    # =======================
    st.markdown(
    """
    <h4 style='
        text-align: center;
        background-color: #4f9ac3;
        color: black;
        padding: 10px;  /* ä¸Šä¸‹24pxã€å·¦å³10px */
        border-radius: 8px;
    '>Top 10 Scanning Regions</h4>
    """,
    unsafe_allow_html=True
    )
    sorted_project_rank = st.session_state.project_rank_card.sort_values(by="Today", ascending=False)


    # ã€ä¿®æ”¹è™•ï¼šç²å–å°ˆæ¡ˆæ’è¡Œæ¦œæ•¸æ“šä¸¦æº–å‚™æœˆä»½å’Œé€±åˆ¥æ¯”è¼ƒæ•¸æ“šã€‘
    project_rank_card = st.session_state.project_rank_card

    # ã€ä¿®æ”¹è™•ï¼šæº–å‚™æœ¬æœˆ vs ä¸Šæœˆçš„Top10æ•¸æ“šï¼Œä¾ç…§ä¸Šæœˆæ’åºã€‘
    monthly_top10 = project_rank_card.sort_values(by="Last Month", ascending=False).head(10)
    monthly_max_value = max(monthly_top10["This Month"].max(), monthly_top10["Last Month"].max())

    # ã€ä¿®æ”¹è™•ï¼šå°‡æœˆä»½è³‡æ–™è½‰ç‚ºé•·æ ¼å¼ã€‘
    monthly_melted = monthly_top10.melt(
        id_vars=["Project Name"],
        value_vars=["This Month", "Last Month"],
        var_name="Duration",
        value_name="Value"
    )

    # ã€ä¿®æ”¹è™•ï¼šæº–å‚™æœ¬é€± vs ä¸Šé€±çš„Top10æ•¸æ“šï¼Œä¾ç…§ä¸Šé€±æ’åºã€‘
    weekly_top10 = project_rank_card.sort_values(by="Last Week", ascending=False).head(10)
    weekly_max_value = max(weekly_top10["This Week"].max(), weekly_top10["Last Week"].max())

    # ã€ä¿®æ”¹è™•ï¼šå°‡é€±åˆ¥è³‡æ–™è½‰ç‚ºé•·æ ¼å¼ã€‘
    weekly_melted = weekly_top10.melt(
        id_vars=["Project Name"],
        value_vars=["This Week", "Last Week"],
        var_name="Duration",
        value_name="Value"
    )

    # ã€ä¿®æ”¹è™•ï¼šå‰µå»ºæœˆä»½æ¯”è¼ƒåœ–è¡¨ã€‘
    fig_monthly = px.bar(
        monthly_melted,
        x="Value",
        y="Project Name",
        color="Duration",
        barmode="group",
        text="Value",
        orientation="h",
        title="",
    )

    # ã€ä¿®æ”¹è™•ï¼šç¾åŒ–æœˆä»½åœ–è¡¨è¨­å®šã€‘
    fig_monthly.update_traces(textposition='outside')
    fig_monthly.update_layout(
        xaxis=dict(
            range=[0, monthly_max_value * 1.3],
            showgrid=True,
            gridwidth=1,
            gridcolor='LightGray',
            title="Scan Counts",
            titlefont=dict(size=12, color='black'),
        ),
        yaxis=dict(
            categoryorder="array",
            categoryarray=monthly_top10.sort_values("Last Month", ascending=True)["Project Name"].tolist(),
            title='Project',
            titlefont=dict(size=12, color='black'),
        ),      
        uniformtext_minsize=8,
        uniformtext_mode='hide',
        bargap=0.3,
        bargroupgap=0.05,
        height=400,
        legend=dict(
            title=None,
            orientation="h",
            yanchor="top",
            y=1.1,
            xanchor="center",
            x=0.5,
        )
    )
    

    # ã€ä¿®æ”¹è™•ï¼šå‰µå»ºé€±åˆ¥æ¯”è¼ƒåœ–è¡¨ã€‘
    fig_weekly = px.bar(
        weekly_melted,
        x="Value",
        y="Project Name",
        color="Duration",
        barmode="group",
        text="Value",
        orientation="h",
        title=""
    )

    # ã€ä¿®æ”¹è™•ï¼šç¾åŒ–é€±åˆ¥åœ–è¡¨è¨­å®šã€‘
    fig_weekly.update_traces(textposition='outside')
    fig_weekly.update_layout(
        xaxis=dict(
            range=[0, weekly_max_value * 1.3],
            showgrid=True,
            gridwidth=1,
            gridcolor='LightGray',
            title="Scan Counts",
            titlefont=dict(size=12, color='black'),       
        ),
        yaxis=dict(
            categoryorder="array",
            categoryarray=weekly_top10.sort_values("Last Week", ascending=True)["Project Name"].tolist(),
            title='Project',
            titlefont=dict(size=12, color='black'),
        ),        
        uniformtext_minsize=8,
        uniformtext_mode='hide',
        bargap=0.3,
        bargroupgap=0.1,
        height=400,
        legend=dict(
            title=None,
            orientation="h",
            yanchor="top",
            y=1.1,
            xanchor="center",
            x=0.5
        )
    )

    # ã€ä¿®æ”¹è™•ï¼šä½¿ç”¨ st.columns(2) å°‡å…©å€‹åœ–è¡¨ä¸¦æ’é¡¯ç¤ºã€‘
    col_monthly, col_weekly = st.columns(2)

    with col_monthly:
        st.markdown('<div class="date-input-row"><label>Monthly Scans</label></div>', unsafe_allow_html=True)
        st.plotly_chart(fig_monthly, use_container_width=True)
    with col_weekly:
        st.markdown('<div class="date-input-row"><label>Weekly Scans</label></div>', unsafe_allow_html=True)
        st.plotly_chart(fig_weekly, use_container_width=True)

    
    # num_columns = 4
    # sorted_project_rank_top6 = sorted_project_rank.head(8)
    # rows = [sorted_project_rank_top6.iloc[i:i+num_columns] for i in range(0, len(sorted_project_rank_top6), num_columns)]
    # # å°‡å¡ç‰‡è³‡æ–™æ¸²æŸ“æˆ HTML markdown æ ¼å¼
    # # å¡ç‰‡ HTML æ¸²æŸ“
    # for row in rows:
    #     cols = st.columns(len(row))
    #     for idx, (_, project) in enumerate(row.iterrows()):
    #         with cols[idx]:
    #             st.markdown(
    #                 f"""
    #                 <div style='background-color: #f0f2f6; padding: 1rem; border-radius: 12px; box-shadow: 0 2px 4px rgba(0,0,0,0.1); font-size: 12px;'>
    #                     <h8 style='margin-bottom: 0.1rem; font-size: 16px;'>{project["Project Name"]}</h8>
    #                     <p style="margin: 0;">â–¶ <b style="color: #0505ff;">This Monthï¼š</b>{int(project["This Month"])}</p>
    #                     <p style="margin: 0;">â–¶ <b>Last Monthï¼š</b>{int(project["Last Month"])}</p>
    #                     <p style="margin: 0;">â–¶ <b style="color: #0505ff;">This Weekï¼š</b>{int(project["This Week"])}</p>
    #                     <p style="margin: 0;">â–¶ <b>Last Weekï¼š</b>{int(project["Last Week"])}</p>
    #                     <p style="margin: 0;">â–¶ <b style="color: #0505ff;">Todayï¼š</b>{int(project["Today"])}</p>
    #                     <p style="margin: 0;">â–¶ <b>Yesterdayï¼š</b>{int(project["Yesterday"])}</p>
    #                 </div>
    #                 """,
    #                 unsafe_allow_html=True
    #             )
    #     st.markdown("<div style='height: 1rem;'></div>", unsafe_allow_html=True)

    # =======================
    # 7-2. è¼¸å…¥æŸ¥è©¢æ—¥æœŸ
    # =======================
    st.markdown(
        "<h4 style='text-align: center; background-color: #4f9ac3; padding: 10px;'>Project Query</h4>",
        unsafe_allow_html=True,
    )
    col1, col2, col3, col4 = st.columns([1,2,1,2])
    with col1:
        st.markdown('<div class="orange-label-row"><label>â±ï¸ Enquiry Start Dateï¼š</label></div>', unsafe_allow_html=True)
    with col2:
        start_date = st.date_input("â±ï¸ Select Star Date", label_visibility = "collapsed",value=default_start_date, max_value=last_scan_time)
        start_date = pd.Timestamp(start_date).replace(hour=0, minute=0).tz_localize("Asia/Taipei")
    with col3:
        st.markdown('<div class="orange-label-row"><label>â±ï¸ Enquiry End Dateï¼š</label></div>', unsafe_allow_html=True)
    with col4:
        end_date = st.date_input("â±ï¸ Select End Date", label_visibility = "collapsed",value=last_scan_time, max_value=last_scan_time)
        end_date = pd.Timestamp(end_date).replace(hour=23, minute=59).tz_localize("Asia/Taipei")

    if start_date > end_date:
        st.error("Error: çµæŸæ—¥æœŸå¿…é ˆå¤§æ–¼ç­‰æ–¼é–‹å§‹æ—¥æœŸ")
        st.stop()


    if ('scan_hash' not in st.session_state or
        'project_hash' not in st.session_state or
        'merge_datefilter' not in st.session_state or
        'merge_prj_scan' not in st.session_state or
        'project_rank' not in st.session_state or
        st.session_state.scan_hash != scan_hash or
        st.session_state.project_hash != project_hash or 
        st.session_state.start_date != start_date or 
        st.session_state.end_date != end_date):

        st.session_state.merge_datefilter = prepare_project_data(filtered_df_project, df_scan, start_date, end_date)
        st.session_state.merge_prj_scan = prepare_project_data_all_time(filtered_df_project, df_scan)
        st.session_state.start_date = start_date
        st.session_state.end_date = end_date
        st.session_state.scan_hash = scan_hash
        st.session_state.project_hash = project_hash
        st.session_state.project_rank = generate_project_rank(st.session_state.merge_datefilter, filtered_df_project,st.session_state.merge_data_yesterday,st.session_state.merge_data_today)

    # =======================
    # 7-2. æ•¸æ“šæ•´ç†
    # =======================
    merge_datefilter = st.session_state.merge_datefilter
    merge_datefilter = split_project_name(merge_datefilter)
    merge_datefilter['coordinate_system_name'] = merge_datefilter.apply(extract_coordinate_name, axis=1)
    merge_datefilter['weekday'] = merge_datefilter['scantime'].dt.weekday  # 0 = Monday, 6 = Sunday
    df_scenelist = pd.read_csv(
        os.path.join(data_root, "scene.csv"),
        encoding="utf-8-sig",
    )
    df_scenelist['Id'] = df_scenelist['Id'].astype(str)
    df_coordinates = get_coordianate_dict_from_server().assign(id=lambda df: df['id'].astype(int))
    df_heatmap = generate_heatmap_data(merge_datefilter)
    df_click_data = st.session_state.df_click_lig
    df_click_data['obj_id'] = df_click_data['obj_id'].astype(int)
    df_click_data['weekday'] = df_click_data['clicktime'].dt.weekday  # 0 = Monday, 6 = Sunday

    sorted_project_rank_Count = st.session_state.project_rank.sort_values(by="Scan Count", ascending=False)
    # top_20 = sorted_project_rank_Count.head(10)
    # max_value = top_20["Scan Count"].max()
    # # å°‡è³‡æ–™è½‰ç‚ºé•·æ ¼å¼ä»¥ç¬¦åˆ px.bar çš„ grouped å‘ˆç¾æ–¹å¼
    # df_melted = top_20.melt(
    #     id_vars=["Project Name"],
    #     value_vars=["Scan Count", "Yesterday Scans", "Today Scans"],
    #     var_name="é¡å‹",
    #     value_name="æ•¸å€¼"
    # )

    # # ç•«ç¾¤çµ„å¼é•·æ¢åœ–
    # fig = px.bar(
    #     df_melted,
    #     x="æ•¸å€¼",
    #     y="Project Name",
    #     color="é¡å‹",
    #     barmode="group",  # å¯æ”¹æˆ 'stack' è©¦è©¦å †ç–Šå¼
    #     text="æ•¸å€¼",
    #     orientation="h",
    #     title="Comparison of Scanning Statistics by Project"
    # )
    # # ç¾åŒ–è¨­å®š
    # fig.update_traces(textposition='outside')
    # fig.update_layout(
    #     xaxis=dict(range=[0, max_value * 1.2]),
    #     xaxis_title="Scans",
    #     yaxis_title="Project",
    #     uniformtext_minsize=8,
    #     uniformtext_mode='hide',
    #     bargap=0.5,
    #     height=600,
    #     legend=dict(
    #         orientation="h",
    #         yanchor="bottom",
    #         y=-0.8,
    #         xanchor="center",
    #         x=0.5
    #     )
    # )
    # st.plotly_chart(fig, use_container_width=True)

    st.markdown('<div class="date-input-row"><label>Scanning HeatMap</label></div>', unsafe_allow_html=True)           
    plot_heatmpy(df_heatmap)

    start_date_str = start_date.strftime("%Y-%m-%d")
    end_date_str = end_date.strftime("%Y-%m-%d")

    date_range_text = f"ï¼ˆ{start_date_str} ~ {end_date_str}ï¼‰"

    st.markdown(f'''
        <div class="date-input-row">
            <label>ğŸ“ŠData Statistics {date_range_text}</label>
        </div>
                '''
        , unsafe_allow_html=True)     
    with st.container():
        col2_1, col2_2, col2_3 = st.columns(3)
        # ä»Šæ—¥ã€æ˜¨æ—¥ã€æœ¬é€±
        with col2_1:   
            display_metric('Today Scans',today_scan)      
            display_metric('Yesterday Scans',yesterday_scan)      
        # ä¸Šé€±ã€æœ¬æœˆã€ä¸Šæœˆ
        with col2_2:
            display_metric('This Week Scans',this_week_scan)  
            display_metric('Last Week Scans',last_week_scan)  
    
        # å…¶ä»–æ•¸æ“šï¼ˆæ ¹æ“šéœ€è¦æ·»åŠ ï¼‰
        with col2_3:
            display_metric('This Month Scans',this_month_scan)  
            display_metric('Last Month Scans',last_month_scan)  

        st.plotly_chart(fig_monthly_scan, use_container_width=True)

        # é¡¯ç¤ºæƒææ’è¡Œ        
        # st.markdown('<div class="date-input-row"><label>Project Scan (Click "Project Name" to see the detail)</label></div>', unsafe_allow_html=True)
        # project_rank = AgGridTable(sorted_project_rank_Count)
        # st.markdown('<div class="date-input-row"><label>Project Selection</label></div>', unsafe_allow_html=True)
        # project_rank_display = AgGridTable(sorted_project_rank_Count)
        shared_data["project_rank"] = st.session_state.project_rank.sort_values(by="Today Scans", ascending=False)
        # åªåœ¨ç¨‹å¼å•Ÿå‹•æ™‚å•Ÿå‹•æ’ç¨‹
        if 'scheduler_started' not in st.session_state:
            st.session_state.scheduler_started = True
            schedule_tasks()
            # åœ¨èƒŒæ™¯åŸ·è¡Œç·’ä¸­é‹è¡Œæ’ç¨‹
            scheduler_thread = threading.Thread(target=run_scheduler, daemon=True)
            scheduler_thread.start()
            logger.info("Scheduler initialized and started")

        # download_csv_button(st.session_state.project_rank,filename='project_rank.csv',label='Download Project Rank')


        col_1,col_2 = st.columns([10,1])
        with col_1.expander("Scan Raw data"):                
            raw_arrange_data = merge_datefilter[['scantime','region','campaign','coordinate_system_name','Light ID']]
            AgGridTable(raw_arrange_data)
        with col_2.expander(''):
            multiplier = st.number_input("Multiplier for charts", min_value=0.1, max_value=10.0, value=1.0, step=0.1)


        st.markdown('<div class="orange-label-row"><label>Select Project for Detail Analysis</label></div>', unsafe_allow_html=True)
        project_options = sorted_project_rank_Count['Project Name'].tolist()
        default_project = project_options[0] if project_options else None
        selected_project_name = st.selectbox(
            "Choose a project to view details:",
            options=project_options,
            index=0 if default_project else None,
            key="selected_project_dropdown",
            label_visibility="collapsed"
        )

        if selected_project_name:
            # å‰µå»ºèˆ‡åŸæœ¬ selected_row ç›¸åŒæ ¼å¼çš„æ•¸æ“š
            selected_row = sorted_project_rank_Count[
                sorted_project_rank_Count['Project Name'] == selected_project_name
            ].copy()
            
            if not selected_row.empty:
                # è½‰æ›ç‚ºèˆ‡åŸæœ¬ AgGrid ç›¸åŒçš„æ ¼å¼
                selected_project = selected_row['Project Name']
                # st.success(f"Selected project: {selected_project_name}")
            else:
                selected_row = None
                st.warning("Selected project not found in data")
        else:
            selected_row = None
            st.info("Please select a project to see details")

        # selected_row = project_rank["selected_rows"]
        # if selected_row is None:
        #     st.write("Select a project to see detail")            
        # else:
        #     selected_project = selected_row['Project Name']


    # =======================
    # 7-3. å°ˆæ¡ˆåƒæ•¸åŠçµ±è¨ˆæ•¸æ“š
    # =======================


    if selected_row is not None:
        selected_project_name = selected_project.iloc[0]
        with st.container():
            st.markdown(
            f"<h4 style='text-align: center; background-color: #4f9ac3; padding: 10px;'>{selected_project_name} Information {date_range_text}</h4>",
            unsafe_allow_html=True,
            )
            col1,col2 = st.columns([3,1])
            with col1:
                col_prj_head, col_prj_sel = st.columns([1,6])
                with col_prj_head:
                    st.markdown('<div class="date-input-row page-title"><label>Project: </label></div>', unsafe_allow_html=True)            
                with col_prj_sel:
                    selected_project = st.selectbox('Select Project', options=selected_project,label_visibility='collapsed')
                prj_filtered_df=merge_datefilter[merge_datefilter['Project Name']==selected_project]
                df_project = st.session_state.df_project

                filtered_ids_list = (
                    prj_filtered_df['Light ID']
                    .dropna()  # å»é™¤ç©ºå€¼
                    .apply(lambda x: ast.literal_eval(x) if isinstance(x, str) else x)  # å®‰å…¨è§£æå­—ç¬¦ä¸²
                    .explode()  # å±•å¹³åµŒå¥—åˆ—è¡¨
                    .drop_duplicates()  # å»é‡ï¼ˆåƒ…é©ç”¨æ–¼ Seriesï¼‰
                    .tolist()  # è½‰æ›ç‚º Python åˆ—è¡¨
                )
                col_id_head, col_id_sel = st.columns([1,6]) 
                with col_id_head:
                    st.markdown('<div class="date-input-row page-title"><label>lig id: </label></div>', unsafe_allow_html=True)
                with col_id_sel:
                    # å¤šé¸æ¡†é¸æ“‡
                    st.multiselect('Select ID', options=filtered_ids_list,default=filtered_ids_list,label_visibility='collapsed')

                col_scene_head, col_scene_sel = st.columns([1,6]) 
                with col_scene_head:
                    st.markdown('<div class="date-input-row page-title"><label>Scenes: </label></div>', unsafe_allow_html=True)
                with col_scene_sel:
                    #ç²å–ARå°è±¡æ•¸æ“š                
                    prjfiltered_scenes_list = (
                        df_project[df_project['Project Name']==selected_project]['Scenes']
                        .dropna()
                        .apply(lambda x: ast.literal_eval(x) if isinstance(x, str) else [])
                        .sum()
                    )
                    select_scenes = st.multiselect(
                        'Select Scene',
                        options=prjfiltered_scenes_list,
                        default=prjfiltered_scenes_list,
                        label_visibility='collapsed',
                        help="Scroll to view all options",
                        max_selections=None,
                    )
                prjfilter_scene_id_list = [int(item.split("-")[0]) for item in prjfiltered_scenes_list]
                extract_arobj_id = [
                    ar_obj['id'] 
                    for scene_id in select_scenes 
                    for ar_obj in fetch_ar_objects(scene_id.split('-')[0])
                ]

                extract_arobj_id = sorted(set(extract_arobj_id))
                
                filtered_df_click_data = df_click_data[df_click_data['obj_id'].isin(extract_arobj_id)].reset_index()
                filtered_df_click_data = df_date_filter(filtered_df_click_data, "clicktime", start_date, end_date)
                #è¨ˆç®—çµ±è¨ˆæ•¸æ“š
                experiment_number = int(len(prj_filtered_df)*multiplier)
                interaction_number, participants_number = calculate_statistics(filtered_df_click_data,multiplier)
                arobj_number = len(extract_arobj_id)
                      
            with col2:
                #æ›´æ–°é é¢æ•¸æ“š
                cola,colb = st.columns(2)
                with cola:
                    display_metric('Scans',experiment_number)
                    display_metric('AR objects',arobj_number)

                with colb:
                    display_metric('Clicks',interaction_number)
                    display_metric('Users',participants_number)   
                       
            # -------------------------
            # ğŸ“Š æ¯æœˆæƒææ•¸é‡åœ–è¡¨ç¹ªè£½å€å¡Š
            # -------------------------
            # st.markdown("### ğŸ“ˆ Monthly Scan Trends for Project: " + selected_project_name)
            merge_prj_scan = st.session_state.merge_prj_scan
            merge_prj_scan_filtered = merge_prj_scan[merge_prj_scan['Project Name'] == selected_project]


            # ç¢ºä¿ scantime æ¬„ä½ç‚º datetime ä¸¦å¸¶æœ‰æ™‚å€ï¼ˆå¦‚ Asia/Taipeiï¼‰
            merge_prj_scan_filtered['scantime'] = pd.to_datetime(merge_prj_scan_filtered['scantime'], errors='coerce')

            # éæ¿¾è¿‘ 12 å€‹æœˆ
            # one_year_ago = pd.Timestamp.now(tz='Asia/Taipei') - pd.DateOffset(months=12)
            df_recent = merge_prj_scan_filtered[merge_prj_scan_filtered['scantime'] >= one_year_ago].copy()

            # åŠ ä¸Šæœˆä»½æ¬„ä½
            df_recent['month'] = df_recent['scantime'].dt.to_period('M').astype(str)

            # è¨ˆç®—æ¯æœˆæƒææ¬¡æ•¸
            monthly_scan_data = df_recent.groupby('month').size().reset_index(name='Scan Count')

            # Y è»¸ä¸Šé™
            max_scan = monthly_scan_data['Scan Count'].max()

            # ç¹ªè£½åœ–è¡¨
            fig_monthly_prj = px.bar(
                monthly_scan_data,
                x='month',
                y='Scan Count',
                text='Scan Count',
                title=f'ğŸ“Š Monthly Scan Count â€“ {selected_project_name}',
                labels={'month': 'æœˆä»½', 'Scan Count': 'æƒææ¬¡æ•¸'},
                height=400
            )

            fig_monthly_prj.update_traces(textposition='outside')
            fig_monthly_prj.update_layout(
                xaxis_tickangle=-45,
                xaxis=dict(type='category'),
                yaxis=dict(range=[0, max_scan * 1.2]),
                bargap=0.7
            )

            st.plotly_chart(fig_monthly_prj, use_container_width=True)


    # =======================
    # 7-4. çµ±è¨ˆåœ–è¡¨ï¼ˆby day & by hourï¼‰
    # =======================
            st.markdown(
                f"<h4 style='text-align: center; background-color: #4f9ac3; padding: 10px;'>Project Scan Diagram {date_range_text}</h4>",
                unsafe_allow_html=True,
            )    
            col_daily_fig, col_daily_table = st.columns([3,1])            
            with col_daily_fig:
                st.markdown(f'<div class="date-input-row"><label>{selected_project} Daily Scans</label></div>', unsafe_allow_html=True)
                dimenssion = st.selectbox('Choose the sampling by', ['lig_id','coordinate_system_name'])  
                # st.write(prj_filtered_df)
                dailyscan_counts,fig_dailyscan_counts = plot_stacked_histogram_with_dual_y_axis(data=prj_filtered_df, start_date=start_date, end_date=end_date,timecol ='scantime',col_name=dimenssion,multiplier=multiplier)
                st.plotly_chart(fig_dailyscan_counts, use_container_width=True)
                download_csv_button(dailyscan_counts,filename=f'{selected_project}_dailyscan_counts.csv',label='Download Daily Scan Counts')

            with col_daily_table:
                st.markdown(f'<div class="date-input-row"><label>Weekly Statistics</label></div>', unsafe_allow_html=True)               
                fig_week_pie = week_pie_fig(prj_filtered_df)

                st.plotly_chart(fig_week_pie, use_container_width=True)

        # =======================
        # 7-4-2. æ™‚é–“åˆ†ä½ˆåœ–
        # =======================  
        col_time_dist_fig,col_weekday_dist = st.columns([3,1])
        with col_time_dist_fig:
            st.markdown(f'<div class="date-input-row"><label>{selected_project} Daily 24-hour Scan Event Distribution</label></div>', unsafe_allow_html=True)
            fig_time_distribution = time_distribution(prj_filtered_df,start_date, end_date)
            st.plotly_chart(fig_time_distribution, use_container_width=True)

        with col_weekday_dist:
            st.markdown('<div class="date-input-row"><label>Day Distribution</label></div>', unsafe_allow_html=True)
            fig_h24_distribution = h24_distribution(merge_datefilter,col_name='scantime')
            st.plotly_chart(fig_h24_distribution, use_container_width=True)

        # æª¢æŸ¥ select_scenes æ˜¯å¦ç‚ºç©º
        if not select_scenes:  # å¦‚æœæ˜¯ç©ºåˆ—è¡¨
            st.warning("è«‹é¸å–ä¸€å€‹å ´æ™¯")  # é¡¯ç¤ºè­¦å‘Šè¨Šæ¯
            st.stop()  # ä¸­æ­¢å¾ŒçºŒä»£ç¢¼åŸ·è¡Œ
        st.markdown(
            "<h4 style='text-align: center; background-color: #4f9ac3; padding: 10px;'>Scenes Interaction Diagram</h4>",
            unsafe_allow_html=True,
        )
        # =======================
        # 7-5. å°ˆæ¡ˆç‰©ä»¶åŠäº’å‹•æ•¸æ“š
        # ======================= 
        col_ckick_fig , col_click_data = st.columns([3,1])
        # ä¸»æµç¨‹ï¼šä¾æ“š ids_list ä¾åºå–å¾—æ‰€æœ‰ ar_objects è³‡æ–™
        all_objects = []
        token = st.session_state.get("_lig_token")
        for scene_id in prjfilter_scene_id_list:
            objs = get_ar_objects_by_scene_id(scene_id,df_scenelist, token=token)
            all_objects.extend(objs)

        # å»ºç«‹ DataFrame df_selected_objï¼Œè‹¥ç„¡è³‡æ–™å‰‡å»ºç«‹ç©º DataFrame
        df_selected_obj = pd.DataFrame(all_objects, columns=["scene_id","scene", "obj_id", "obj_name","location_x","location_y","location_z"])
        
        # æ¥ä¸‹ä¾†ï¼Œèˆ‡é»æ“Šè¨˜éŒ„ filtered_df_click_lig ä¾æ“š 'obj_id' èåˆï¼Œæ–°å¢ 'obj_name' æ¬„ä½
        filtered_df_click_obj = pd.merge(filtered_df_click_data, df_selected_obj, on="obj_id", how="left")
        filtered_df_click_obj["click_date_only"] = filtered_df_click_obj["clicktime"].dt.normalize()
        filtered_df_click_obj["ar_obj"] = filtered_df_click_obj["obj_id"].astype(str) + " - " + filtered_df_click_obj["obj_name"].astype(str)
        
        click_daily_counts, fig_dailyclick = plot_stacked_histogram_with_dual_y_axis(filtered_df_click_obj, start_date, end_date, timecol ='clicktime',col_name='scene', multiplier=multiplier)


        with col_ckick_fig:            
            st.markdown(f'<div class="date-input-row"><label>{selected_project} Daily Click Histogram</label></div>', unsafe_allow_html=True)
            st.plotly_chart(fig_dailyclick, use_container_width=True)
            download_csv_button(df=click_daily_counts, filename=f'{selected_project}_dailyclick.csv', label='Download Daily Click CSV')
            with st.expander("click raw data"):
                st.write(filtered_df_click_obj)
        with col_click_data:
            with st.container():            
                st.markdown(f'<div class="date-input-row"><label>Weekly Statistics</label></div>', unsafe_allow_html=True)
                st.markdown('<div class="plotly-chart-container">', unsafe_allow_html=True)
                fig_click_week_pie = week_pie_fig(filtered_df_click_obj)
                st.plotly_chart(fig_click_week_pie, use_container_width=True)            
                st.markdown('</div>', unsafe_allow_html=True)
            
        # ----------------------------
        # (2) è£½ä½œç‰©ä»¶é»æ“Šæ’è¡Œæ¦œ
        # ----------------------------        
        click_scene_list = filtered_df_click_obj['scene'].unique()
        if click_scene_list is None:
            st.warning("âš ï¸ æ²’æœ‰å¯ç”¨çš„å ´æ™¯æ•¸æ“šï¼Œè«‹æª¢æŸ¥ click_scene_list!")
        else:    
            st.markdown(
                f"<h4 style='text-align: center; background-color: #4f9ac3; padding: 10px;'>Scenes Interaction Diagram {date_range_text}</h4>",
                unsafe_allow_html=True,
            )                
            sc = st.selectbox('Choose a Scene',options=click_scene_list)

            filtered_click_obj_sc = filtered_df_click_obj[filtered_df_click_obj['scene'] == sc]
            fig_clcikobjdist,ranking = clickobjdist(filtered_click_obj_sc,multiplier)

            # ç”Ÿæˆæ–‡å­—é›²

            word_freq = dict(zip(ranking["ar_obj"], ranking["click_count"]))
            
            # ç”Ÿæˆæ©¢åœ“å½¢é®ç½©
            mask = np.zeros((400, 800), dtype=np.uint8)
            image = Image.new("L", (800, 400))
            draw = ImageDraw.Draw(image)
            draw.ellipse((10, 10, 790, 390), fill=255)  # ç•«ä¸€å€‹æ©¢åœ“å½¢
            mask = np.array(image)

            # åè½‰é®ç½©ï¼šç™½è‰²è®Šç‚ºé»‘è‰²ï¼Œé»‘è‰²è®Šç‚ºç™½è‰²
            mask = 255 - mask  # æ©¢åœ“å½¢å…§è®Šç‚º 0ï¼ˆå…è¨±æ”¾ç½®æ–‡å­—ï¼‰ï¼Œæ©¢åœ“å½¢å¤–è®Šç‚º 255ï¼ˆä¸å…è¨±æ”¾ç½®æ–‡å­—ï¼‰
            
            # è‡ªè¨‚éš¨æ©Ÿé¡è‰²å‡½æ•¸
            def random_color_func(word, font_size, position, orientation, random_state=None, **kwargs):
                if font_size > 100:  # å‡è¨­å­—é«”å¤§å°å¤§æ–¼100çš„è©å½™æ˜¯ä¸­å¿ƒè©ï¼Œè¨­ç‚ºç¶ è‰²
                    return "hsl(120, 60%, 40%)"  # ç¶ è‰²
                else:
                    # éš¨æ©Ÿç”Ÿæˆå…¶ä»–é¡è‰²
                    h = random.randint(0, 360)  # è‰²ç›¸
                    s = random.randint(50, 100)  # é£½å’Œåº¦
                    l = random.randint(30, 70)  # äº®åº¦
                    return f"hsl({h}, {s}%, {l}%)"
            
            # ç”Ÿæˆæ–‡å­—é›²
            wordcloud = WordCloud(
                width=800, 
                height=400, 
                background_color="white",
                mask=mask,  # ä½¿ç”¨æ©¢åœ“å½¢é®ç½©
                contour_width=0,  # ä¸é¡¯ç¤ºé®ç½©é‚Šæ¡†
                font_path="font/msjh.ttc",  # æŒ‡å®šä¸­æ–‡å­—é«”ï¼ˆæ ¹æ“šä½ çš„ç³»çµ±è·¯å¾‘èª¿æ•´ï¼‰
                color_func=random_color_func,  # ä½¿ç”¨è‡ªè¨‚é¡è‰²å‡½æ•¸
                min_font_size=10, 
                max_font_size=100,
                relative_scaling=0.15,  # é™ä½ç¸®æ”¾æ¯”ä¾‹ï¼Œè®“æ–‡å­—åˆ†ä½ˆæ›´å‡å‹»
                prefer_horizontal=50,  # é™ä½æ°´å¹³æ’åˆ—æ¯”ä¾‹ï¼Œè®“æ–‡å­—æ›´éˆæ´»
                max_words=100,  # ç¢ºä¿æ‰€æœ‰è©å½™éƒ½èƒ½é¡¯ç¤º
                scale=5,  # å¢åŠ å¯†åº¦ï¼Œè®“æ–‡å­—æ›´å±•é–‹
                random_state=100,  # å›ºå®šéš¨æ©Ÿç¨®å­ï¼Œå˜—è©¦è®“å¤§å­—æ›´æ¥è¿‘ä¸­é–“
            ).generate_from_frequencies(word_freq)
            
            ranking = ranking[['ar_obj', 'click_count']]
            # æ’åºè³‡æ–™ï¼Œé¸å‰10åå¯è¦–éœ€æ±‚èª¿æ•´
            ranking_sorted = ranking.sort_values(by="click_count", ascending=True)  # å°åˆ°å¤§ for horizontal bar
            fig_h24_clickdistribution = h24_distribution(filtered_click_obj_sc,col_name='clicktime')

            fig_ranking_bar = px.bar(
                ranking_sorted,
                x="click_count",
                y="ar_obj",
                orientation="h",  # æ°´å¹³ç›´æ–¹åœ–
                text="click_count",
                labels={"ar_obj": "é»æ“Šç‰©ä»¶", "click_count": "é»æ“Šæ¬¡æ•¸"},
                title="Object Click Ranking"
            )

            # ç¾åŒ–è¨­å®š
            fig_ranking_bar.update_layout(
                height=600,
                width=400,
                margin=dict(t=40, b=40),
                xaxis_title="Click Count",
                yaxis_title="Click Object",
            )
            fig_ranking_bar.update_traces(textposition='outside')

            col_word, col_clickrank = st.columns([6,4])
            with col_word:
                # ä½¿ç”¨ matplotlib é¡¯ç¤º
                plt.figure(figsize=(8, 5))
                plt.imshow(wordcloud, interpolation="bilinear")
                plt.axis("off")
                st.pyplot(plt)
            with col_clickrank:                            
                st.plotly_chart(fig_ranking_bar, use_container_width=True)


            col_f,col_t = st.columns([3,1])
            with col_f:
                st.markdown(f'<div class="date-input-row"><label>{sc} Object Location Click Distribution </label></div>', unsafe_allow_html=True)

                # st.write(ranking)
                if fig_clcikobjdist is None:
                    st.error(f"ğŸš¨ ç„¡æ³•ç”Ÿæˆå ´æ™¯ {sc} çš„é»æ“Šåˆ†ä½ˆåœ–ï¼Œè«‹æª¢æŸ¥æ•¸æ“šï¼")
                else:
                    st.plotly_chart(fig_clcikobjdist, use_container_width=True)
                    
                
            with col_t:
                st.markdown(f'<div class="date-input-row"><label>Click Object Ranks</label></div>', unsafe_allow_html=True)    
                
                if ranking is None:
                    st.warning(f"âš ï¸ å ´æ™¯ {sc} çš„æ’è¡Œæ¦œæ•¸æ“šç‚ºç©ºï¼")
                else:
                    # st.dataframe(ranking,use_container_width=True,height=300, hide_index=True)
                    st.plotly_chart(fig_h24_clickdistribution, use_container_width=True)
                

        st.markdown(
            f"<h4 style='text-align: center; background-color: #4f9ac3; padding: 10px;'>{selected_project} User Data {date_range_text}</h4>",
            unsafe_allow_html=True,
        )
        # ----------------------------
        # (2) æ¯æ—¥åƒèˆ‡äººæ•¸çµ±è¨ˆ
        # ----------------------------    

        daily_users, fig_user_counts = user_data_fig(filtered_click_obj_sc,start_date,end_date)
        # é¡¯ç¤ºåœ–è¡¨
        st.plotly_chart(fig_user_counts, use_container_width=True)

        # =======================
        st.markdown(
            f"<h4 style='text-align: center; background-color: #4f9ac3; padding: 10px;'>{selected_project} é«”é©—æ™‚é–“åˆ†æ {date_range_text}</h4>",
            unsafe_allow_html=True,
        )

        experience_df = compute_multi_experiences(filtered_df_click_obj)

        col_ex1, col_ex2 = st.columns([2, 1])
        with col_ex1:
            st.markdown(f'<div class="date-input-row"><label>{sc} é«”é©—æ®µè½é•·æ¢åœ–</label></div>', unsafe_allow_html=True)
            fig_bar = plot_user_experience_bar(experience_df, selected_scene=sc)
            st.plotly_chart(fig_bar, use_container_width=True)

        with col_ex2:
            st.markdown(f'<div class="date-input-row"><label>{sc} é«”é©—æ™‚é–“åˆ†å¸ƒ Box Plot</label></div>', unsafe_allow_html=True)
            fig_box = plot_experience_box(experience_df, selected_scene=sc)
            st.plotly_chart(fig_box, use_container_width=True)
        # =======================


        st.markdown(f'<div class="date-input-row"><label>{sc} User Interaction Path</label></div>', unsafe_allow_html=True)
 


        col_userrank, col_path_log = st.columns([1,2])
        with col_userrank:
            user_ranking = generate_user_id_ranking(filtered_click_obj_sc)
            user_ranking_table = AgGridTable(user_ranking)
        with col_path_log:
            selected_row = user_ranking_table["selected_rows"]          
            if selected_row is None:
                selected_user = filtered_click_obj_sc['user_id'].iloc[0]
                st.write("Select a project to see detail")            
            else:
                selected_user = str(selected_row['user_id'].iloc[0])
            fig_clcikobjdist,merge_ranking = clickobjdist(filtered_df_click_obj,multiplier)
            user_data = filtered_df_click_obj[filtered_df_click_obj['user_id']==selected_user]
            fig_with_path, user_data = clickobjdist_with_userpath(fig_clcikobjdist,user_data, multiplier=1.0)

            user_data['click_date'] = pd.to_datetime(user_data['clicktime']).dt.date
            available_dates = sorted(user_data['click_date'].unique())
            date_options = [date.strftime('%Y-%m-%d') for date in available_dates]
            st.write(f'{selected_user} click path')
            selected_dates = st.multiselect(
                "Select Dates to Display",
                options=date_options,
                default=date_options,  # é è¨­å…¨é¸
                key=f"date_select_{selected_user}"  # ç¢ºä¿æ¯å€‹ç”¨æˆ¶çš„é¸æ“‡ç¨ç«‹
            )
          # æ ¹æ“šé¸æ“‡çš„æ—¥æœŸéæ¿¾ user_data
            if selected_dates:
                filtered_user_data = user_data[user_data['click_date'].isin(
                    [pd.to_datetime(date).date() for date in selected_dates]
                )]
            else:
                filtered_user_data = user_data  # å¦‚æœæœªé¸æ“‡æ—¥æœŸï¼Œé¡¯ç¤ºæ‰€æœ‰æ•¸æ“š            
            st.dataframe(
                filtered_user_data[['clicktime','ar_obj']],
                use_container_width=True,
                height=300, 
                hide_index=True
            )

        st.plotly_chart(fig_with_path, use_container_width=True)
        
        with st.expander("user information raw ddata"):
            st.write(daily_users)

        # =======================
        # 7-5. é¸æ“‡ç‰©ä»¶çœ‹é»æ“Šæ’è¡Œ
        # ======================= 
        with st.expander("Custom Object Clicks"):
            st.markdown(f'<div class="date-input-row"><label>{selected_project} Custom Object Clicks</label></div>', unsafe_allow_html=True)         
            col_obj, col_rank = st.columns(2)
            with col_obj:
                def extract_obj_name(ar_obj):
                    return ar_obj.split(' - ')[-1]
                # Add scene selection
                scene_options = sorted(filtered_df_click_obj['scene'].unique())  # Assuming there's a 'scene' column
                selected_scenes = st.multiselect('Choose Scenes', options=scene_options)
                
                # Filter dataframe based on selected scenes
                if selected_scenes:
                    scene_filtered_df = filtered_df_click_obj[filtered_df_click_obj['scene'].isin(selected_scenes)]
                else:
                    scene_filtered_df = filtered_df_click_obj

                ar_obj_options = sorted(scene_filtered_df['ar_obj'].unique(), key=lambda x: extract_obj_name(x))
                # ar_obj_options = sorted(filtered_df_click_obj['ar_obj'].unique(), key=lambda x: extract_obj_name(x))
                
                # ar_obj_options = merged_clicks['ar_obj'].unique()
                st.markdown("""
                <style>
                .stMultiSelect .select-multi-item div {
                    white-space: normal !important;
                    font-size: 8px;
                    word-wrap: break-word;
                    max-width: 100%;
                }
                </style>
                """, unsafe_allow_html=True)

                # st.write(filtered_df_click_obj)
                selected_ar_objs = st.multiselect('Choose AR Objects', options=ar_obj_options)
                # éæ¿¾é¸æ“‡çš„ar_obj
                if selected_ar_objs:
                    filtered_clicks = filtered_df_click_obj[filtered_df_click_obj['ar_obj'].isin(selected_ar_objs)]
                else:
                    filtered_clicks = filtered_df_click_obj        
                filtered_ranking = (
                    filtered_clicks.groupby(["ar_obj"])
                    .size()
                    .reset_index(name="click_count")        
                    .sort_values("click_count", ascending=False)
                )

            with col_rank:
                if not selected_ar_objs:
                    st.write("Choose AR Objects to check the click counts")
                else:
                    st.dataframe(filtered_ranking, use_container_width=True)
                download_csv_button(filtered_ranking,filename=f'{selected_project}_custmon_clickcount.csv',label='Download Custmon ClickCounts')

def parameters():
    """View: æ›´æ–° Dashboard è¨­å®š"""
    project_filepath = os.path.join("data", "projects_new_0306.csv")
    df_project_edit = load_data(project_filepath)
    st.info("Projects Table")
    st.session_state.coordinates_list_option = get_coordinates_list_from_server()
    st.session_state.light_ids_option = get_id_list_from_file()
    df_scenelist = pd.read_csv(
        os.path.join(data_root, "scene.csv"),
        encoding="utf-8-sig",
    )
    scanlist_option  = df_scenelist.apply(lambda row: f"{row['Id']}-{row['Name']}", axis=1).tolist()
    st.session_state.scenes_option = scanlist_option
    user_login_email = st.session_state.get("logged_in_user", "")

    # å¦‚æœ email_options æœªåŒ…å«ç•¶å‰ä½¿ç”¨è€…ï¼Œå‹•æ…‹æ·»åŠ 
    if user_login_email:
        if user_login_email not in st.session_state.email_options:
            st.session_state.email_options.append(user_login_email)


    def save_uploaded_file(uploaded_file, path):
        """ä¿å­˜ä¸Šå‚³çš„æª”æ¡ˆ"""
        try:
            # ç¢ºä¿ç›®éŒ„å­˜åœ¨
            os.makedirs(path, exist_ok=True)
            
            # å»ºç«‹å®Œæ•´è·¯å¾‘
            file_path = os.path.join(path, uploaded_file.name)
            
            # å¯«å…¥æª”æ¡ˆ
            with open(file_path, "wb") as f:
                f.write(uploaded_file.getbuffer())
            
            st.success(f"æª”æ¡ˆå·²ä¿å­˜è‡³ï¼š{file_path}")
        except PermissionError:
            st.error("æ¬Šé™éŒ¯èª¤ï¼šè«‹æª¢æŸ¥ç›®éŒ„å¯«å…¥æ¬Šé™")
        except OSError as e:
            st.error(f"å­˜å„²å¤±æ•—ï¼š{e}ï¼ˆå¯èƒ½æ˜¯ç£ç¢Ÿç©ºé–“ä¸è¶³ï¼‰")
        except Exception as e:
            st.error(f"æœªçŸ¥éŒ¯èª¤ï¼š{e}")

    def save_data(df,filepath):
        max_backups = 5
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        bakcup_filepath  = os.path.join("data", f"projects.csv.backup_{timestamp}")
        df['Start Date'] = pd.to_datetime(df['Start Date'], format='%Y-%m-%d', errors='coerce')        
        df['End Date'] = pd.to_datetime(df['End Date'], format='%Y-%m-%d', errors='coerce')        
        df['Start Date'] = df['Start Date'].apply(lambda x: x.strftime('%Y-%m-%d') if pd.notnull(x) else '')
        df['End Date'] = df['End Date'].apply(lambda x: x.strftime('%Y-%m-%d') if pd.notnull(x) else '')
        df['Owner Email'] = df['Owner Email'].apply(json.dumps)
        try:
            df.to_csv(filepath, encoding="utf-8-sig", index=False)   # /data/projects.csv
            df.to_csv(bakcup_filepath, encoding="utf-8-sig", index=False) #/data/projects.csv.backup_20250102234210
            backup_files = sorted(glob.glob(f'data/projects.csv.backup_*'))
            st.write(backup_files)
            while len(backup_files) > max_backups:
                oldest_backup = backup_files.pop(0)
                os.remove(oldest_backup)
            st.success("Saved successfully!")
        except Exception as e:
            print(f"Failed to save the file: {e}")
        df['Owner Email'] = df['Owner Email'].apply(json.loads)

    def fetch_coordinates_from_server(light_id):
        url = f"{CORE_API_SERVER}/api/v1/lightids/{light_id}"
        try:
            response = requests.get(url)
            response.raise_for_status()
            data = response.json()
            cs_list = data.get("cs_list", [])
            return [f'{cs["id"]}-{cs["name"]}' for cs in cs_list]
        except requests.exceptions.RequestException as e:
            st.error(f"Failed to fetch coordinates for Light ID {light_id}: {e}")
            return []

    def add_project(df_project_edit):
        st.subheader("Add New Project")
        user_login_email = st.session_state.get("logged_in_user", "")

        # ä½¿ç”¨è¼”åŠ©è®Šæ•¸æ§åˆ¶ new_email çš„é¡¯ç¤ºå€¼
        if "new_email_input" not in st.session_state:
            st.session_state.new_email_input = ""

        with st.container():
            st.text_input("Project Name", value="", key="project_name_new")
            st.date_input("Start Date", value=datetime.now().date(), key="start_date_new")
            st.date_input("End Date", value=datetime.now().date(), key="end_date_new")
            st.checkbox("Active", value=False, key="is_active_new")
            st.text_input("Latitude and Longitude", value="", key="lat_lon_new")
            st.multiselect(
                "Light IDs",
                options=st.session_state.light_ids_option,
                default=[],
                key="light_ids_input_new",
            )
            coordinates_list = []
            for light_id in st.session_state.light_ids_input_new:
                new_coordinates = fetch_coordinates_from_server(light_id)
                coordinates_list.extend(new_coordinates)
                coordinates_list = list(set(coordinates_list))
            st.multiselect(
                "Coordinates",
                options=st.session_state.coordinates_list_option,
                default=coordinates_list,
                key="coordinates_input_new",
            )
            st.multiselect(
                "Scenes",
                options=st.session_state.scenes_option,
                default=[],
                key="scenes_input_new",
            )

            #ä½¿ç”¨è¡¨å–®è™•ç†æ–°é›»å­éƒµä»¶è¼¸å…¥
            with st.form(key="email_form", clear_on_submit=True):
                new_email = st.text_input("Add New Owner Email", value="", key="new_owner_email")
                submit_email = st.form_submit_button("Add Email")
                if submit_email and new_email and new_email not in st.session_state.email_options:
                    st.session_state.email_options.append(new_email)  # æ·»åŠ å®Œæ•´å­—ä¸²
                    st.rerun()


            default_emails = [user_login_email] if user_login_email else []

            st.multiselect(
                "Owner Emails",
                options=st.session_state.email_options,
                default=default_emails,
                key="owner_emails_new"
            )
            st.write(f"Selected owner_emails_new: {st.session_state.owner_emails_new}")
            add_button = st.button(label="Add Project",use_container_width=True)

            if add_button:
                if not st.session_state.project_name_new.strip():
                    st.error("Project Name cannot be empty.")
                elif pd.notnull(st.session_state.start_date_new) and st.session_state.end_date_new < st.session_state.start_date_new:
                    st.error("End Date cannot be earlier than Start Date.")
                else:

                    # æª¢æŸ¥ df_project_edit æ˜¯å¦æœ‰æ•ˆ
                    if df_project_edit is None or df_project_edit.empty:
                        st.error("ç„¡æ³•è¼‰å…¥å°ˆæ¡ˆæ•¸æ“šï¼Œè«‹æª¢æŸ¥è³‡æ–™ä¾†æºï¼")
                        return

                    new_project_id = (
                        df_project_edit['ProjectID'].astype(int).max() + 1
                        if not df_project_edit.empty
                        else 1
                    )
                    new_project = {
                        'ProjectID': new_project_id,
                        'Project Name': st.session_state.project_name_new,
                        'Start Date': st.session_state.start_date_new,
                        'End Date': st.session_state.end_date_new,
                        'Coordinates': json.dumps(st.session_state.coordinates_input_new, ensure_ascii=False),
                        'Light ID': json.dumps(st.session_state.light_ids_input_new, ensure_ascii=False),
                        'Scenes': json.dumps(st.session_state.scenes_input_new, ensure_ascii=False),
                        'Is Active': st.session_state.is_active_new,
                        'Latitude and Longitude': st.session_state.lat_lon_new,
                        'Owner Email': st.session_state.owner_emails_new,
                    }
                    df_new_project = pd.DataFrame([new_project])
                    df_new_project['Start Date'] = pd.to_datetime(df_new_project['Start Date'], format='%Y-%m-%d', errors='coerce')
                    df_new_project['End Date'] = pd.to_datetime(df_new_project['End Date'], format='%Y-%m-%d', errors='coerce')
                    df_new_project['Start Date'] = df_new_project['Start Date'].apply(lambda x: x.strftime('%Y-%m-%d') if pd.notnull(x) else '')
                    df_new_project['End Date'] = df_new_project['End Date'].apply(lambda x: x.strftime('%Y-%m-%d') if pd.notnull(x) else '')
                    df_project_edit['Start Date'] = pd.to_datetime(df_project_edit['Start Date'], format='%Y-%m-%d', errors='coerce')
                    df_project_edit['End Date'] = pd.to_datetime(df_project_edit['End Date'], format='%Y-%m-%d', errors='coerce')
                    df_project_edit['Start Date'] = df_project_edit['Start Date'].apply(lambda x: x.strftime('%Y-%m-%d') if pd.notnull(x) else '')
                    df_project_edit['End Date'] = df_project_edit['End Date'].apply(lambda x: x.strftime('%Y-%m-%d') if pd.notnull(x) else '')
                    df_concat = pd.concat([df_project_edit, df_new_project], ignore_index=True)
                    df_project_edit = df_concat
                    st.session_state.editing_row_index = None
                    save_data(df_concat, project_filepath)
                    del st.session_state.project_name_new
                    del st.session_state.start_date_new
                    del st.session_state.end_date_new
                    del st.session_state.coordinates_input_new
                    del st.session_state.light_ids_input_new
                    del st.session_state.scenes_input_new
                    del st.session_state.is_active_new
                    del st.session_state.lat_lon_new
                    st.rerun()

    def edit_project(selected): # ç¼–è¾‘é¡¹ç›®
        project_info = process_selected_row(pd.DataFrame(selected))
        project_id_default = project_info['ProjectID']
        project_name_default = project_info['Project Name']
        project_start_date_default = project_info['Start Date'] if pd.notnull(project_info['Start Date']) else datetime.now().date()  # æä¾›ä¸€å€‹é è¨­å€¼
        project_end_date_default = project_info['End Date'] if pd.notnull(project_info['End Date']) else datetime.now().date()
        project_coordinates_default = project_info['Coordinates']
        project_light_id_default = project_info['Light ID']
        project_scenes_default = project_info['Scenes']
        project_is_active_default = project_info['Is Active']
        project_lat_lon_default = project_info['Latitude and Longitude']
        project_owner_emails_default = project_info.get('Owner Email')
        project_is_active_default = str(project_is_active_default).upper() == 'TRUE'
        # ç¢ºä¿ project_owner_emails_default æ˜¯åˆ—è¡¨
        if isinstance(project_owner_emails_default, str):
            try:
                project_owner_emails_default = json.loads(project_owner_emails_default)  # è§£æ JSON å­—ä¸²
            except json.JSONDecodeError:
                project_owner_emails_default = [project_owner_emails_default]  # å¦‚æœä¸æ˜¯ JSONï¼Œä½œç‚ºå–®ä¸€å­—ä¸²è™•ç†
        elif not isinstance(project_owner_emails_default, list):
            project_owner_emails_default = []
        # å‹•æ…‹æ›´æ–° email_optionsï¼ŒåŒ…å« project_owner_emails_default ä¸­çš„æ‰€æœ‰å€¼
        for email in project_owner_emails_default:
            if email and email not in st.session_state.email_options:
                st.session_state.email_options.append(email)

        st.subheader(f"Edit Project Id: {project_id_default}")
        with st.container():
            st.text_input('Project Name', value=project_name_default, key="project_name_new")
            st.date_input("Start Date", value=project_start_date_default, key="start_date_new")
            st.date_input("End Date", value=project_end_date_default, key="end_date_new")
            st.checkbox("Active", value=project_is_active_default, key="is_active_new")
            st.text_input("Latitude and Longitude", value=project_lat_lon_default, key="lat_lon_new")

            if isinstance(project_light_id_default,list):
                st.multiselect(
                    "Light IDs",
                    options=st.session_state.light_ids_option,
                    default=project_light_id_default,
                    key="light_ids_input_new",
                )
            if isinstance(project_light_id_default,str):                
                st.multiselect(
                    "Light IDs",
                    options=st.session_state.light_ids_option,
                    default=json.loads(project_light_id_default),
                    key="light_ids_input_new",
                )
            coordinates_list = []
            for light_id in st.session_state.light_ids_input_new:
                new_coordinates = fetch_coordinates_from_server(light_id)
                coordinates_list.extend(new_coordinates)
                coordinates_list = list(set(coordinates_list))
            
            default_coords = json.loads(project_coordinates_default)
            valid_coords = [c for c in default_coords if c in st.session_state.coordinates_list_option]
            invalid_coords = [c for c in default_coords if c not in st.session_state.coordinates_list_option]
            if invalid_coords:
                st.warning(f"ä»¥ä¸‹åº§æ¨™ä¸å­˜åœ¨æ–¼ç›®å‰é¸é …ä¸­ï¼š{invalid_coords}")

            st.multiselect(
                "Coordinates",
                options=st.session_state.coordinates_list_option,
                default=valid_coords,
                key='coordinates_input_new'
            )
            st.multiselect(
                "Scenes",
                options=st.session_state.scenes_option,
                default=json.loads(project_scenes_default),
                key="scenes_input_new",
            )
            with st.form(key="email_form_edit", clear_on_submit=True):
                new_email = st.text_input("Add New Owner Email", value="", key="new_owner_email_edit")
                submit_email = st.form_submit_button("Add Email")
                if submit_email and new_email and new_email not in st.session_state.email_options:
                    st.session_state.email_options.append(new_email)
                    st.rerun()

            st.multiselect(
                "Owner Emails",
                options=st.session_state.email_options,
                default=project_owner_emails_default,
                key="owner_emails_new"
            )
            update_button = st.button(label="Update Project",use_container_width=True)
            # submit_button = st.form_submit_button(label='Update Project')

        if update_button:
            if not st.session_state.project_name_new.strip():
                st.error("Project Name cannot be empty.")
            elif pd.notnull(st.session_state.end_date_new) and st.session_state.end_date_new < st.session_state.start_date_new:
                st.error("End Date cannot be earlier than Start Date.")
            elif not st.session_state.owner_emails_new:
                st.error("At least one Owner Email is required.")
            else:
                st.session_state.coordinates_list = []
                df_project_edit.at[int(st.session_state.editing_row_index), "Project Name"] = st.session_state.project_name_new
                df_project_edit.at[int(st.session_state.editing_row_index), "Start Date"] = st.session_state.start_date_new
                df_project_edit.at[int(st.session_state.editing_row_index), "End Date"] = st.session_state.end_date_new
                df_project_edit.at[int(st.session_state.editing_row_index), "Is Active"] = st.session_state.is_active_new
                df_project_edit.at[int(st.session_state.editing_row_index), "Latitude and Longitude"] = st.session_state.lat_lon_new
                df_project_edit.at[int(st.session_state.editing_row_index), "Coordinates"] = json.dumps(
                    st.session_state.coordinates_input_new, ensure_ascii=False
                )
                df_project_edit.at[int(st.session_state.editing_row_index), "Light ID"] = json.dumps(
                    st.session_state.light_ids_input_new, ensure_ascii=False
                )
                df_project_edit.at[int(st.session_state.editing_row_index), "Scenes"] = json.dumps(
                    st.session_state.scenes_input_new, ensure_ascii=False
                )
                df_project_edit.at[int(st.session_state.editing_row_index), "Owner Email"] = st.session_state.owner_emails_new
                save_data(df_project_edit, project_filepath)
                st.success("Project updated successfully!")
                st.session_state.editing_row_index = None
                st.rerun()

    def process_selected_row(selected):

        if not selected.empty:
            selected_row = selected.iloc[0]           
            try:
                project_id = int(selected_row.get('ProjectID', None))
            except (ValueError, TypeError):
                project_id = None

            project_data = {
                "ProjectID": project_id,
                "Project Name": selected_row.get('Project Name', None),
                "Start Date": pd.to_datetime(selected_row.get('Start Date', None), errors='coerce'),
                "End Date": pd.to_datetime(selected_row.get('End Date', None), errors='coerce'),
                "Coordinates": selected_row.get('Coordinates', None),
                "Light ID": selected_row.get('Light ID', None),
                "Scenes": selected_row.get('Scenes', None),
                "Is Active": selected_row.get('Is Active', None),  
                "Latitude and Longitude": selected_row.get('Latitude and Longitude', None),
                "Owner Email": selected_row.get('Owner Email', []),                    
                "Row Index": selected.index.values[0],
            }

            # æ›´æ–° session_state ä¸­çš„ç¼–è¾‘ç´¢å¼•
            select_row_index = project_data["Row Index"]
            st.session_state.editing_row_index = select_row_index

            return project_data
        else:
            # st.write("No row selected.")
            st.session_state.editing_row_index = None
            return None

    def display_aggrid(df):        
        # å‡†å¤‡æ˜¾ç¤ºçš„ DataFrameï¼Œå°†æ—¥æœŸå’Œåˆ—è¡¨è½¬æ¢ä¸ºå­—ç¬¦ä¸²
        # df_reorder = df[::-1].copy()
        gb = GridOptionsBuilder.from_dataframe(df)
        gb.configure_selection('single', use_checkbox=True, groupSelectsChildren=False)
        gb.configure_default_column(editable=True, sortable=True, filter=True)
        gb.configure_column("ProjectID", editable=False)
        gb.configure_column("Coordinates", editable=False)
        gb.configure_column("Light ID", editable=False)
        gb.configure_column("Scenes", editable=False)
        gb.configure_column("Is Active", editable=False)
        gb.configure_column("Latitude and Longitude", editable=False)
        gb.configure_column("Owner Email", editable=False)
        grid_options = gb.build()

        grid_response = AgGrid(
            df,
            gridOptions=grid_options,
            update_mode=GridUpdateMode.SELECTION_CHANGED,
            allow_unsafe_jscode=True,
            height=500,
            theme='streamlit',
            # return_mode='AS_INPUT',
            fit_columns_on_grid_load=True,
            ColumnsAutoSizeMode="FIT_ALL_COLUMNS_TO_VIEW",
            reload_data = True,
            # data_return_mode='AS_INPUT'  # ç¡®ä¿è¿”å›çš„æ˜¯ç¼–è¾‘åçš„ DataFrame
        )    
        return grid_response

    grid_response = display_aggrid(df_project_edit)

    st.divider()

    selected = pd.DataFrame(grid_response.get('selected_rows', []))

    if not selected.empty:
        st.session_state.editing_row_index = selected.index.values[0]
    else:
        st.session_state.editing_row_index = None

    #å¦‚æœæœ‰é¸ä¸­è¡Œçš„è©±ï¼Œé¡¯ç¤ºç·¨è¼¯è¡¨å–®
    if st.session_state.editing_row_index is not None:
        edit_project(selected)
    else:
        add_project(df_project_edit)
        

    st.divider()
        # æ·»åŠ  Logout æŒ‰éˆ•
    if st.button("Logout"):
        logout()  # èª¿ç”¨ logout å‡½æ•¸

    with st.expander("Clear st.session_status.df_project"):
        st.markdown(
            "<h4 style='text-align: center; background-color: #4f9ac3; padding: 10px;'>File Management</h4>",
            unsafe_allow_html=True,
        )

        data_folder = "data"
        file_options = [f for f in os.listdir(data_folder) if os.path.isfile(os.path.join(data_folder, f))]

        # é¸æ“‡è¦ä¸‹è¼‰çš„æª”æ¡ˆ
        selected_file = st.selectbox('Choose a File', file_options)

        # å‰µå»ºä¸‹è¼‰æŒ‰éˆ•
        if st.button('Download'):
            file_path = os.path.join(data_folder, selected_file)
            with open(file_path, "rb") as file:
                file_bytes = file.read()
                b64_file = base64.b64encode(file_bytes).decode()
                href = f'<a href="data:file/txt;base64,{b64_file}" download="{selected_file}">é»æ“Šæ­¤è™•ä¸‹è¼‰ {selected_file}</a>'
                st.markdown(href, unsafe_allow_html=True)

        uploaded_file = st.file_uploader("Choose Upload File", type=["csv", "txt"])

        # ä¸Šå‚³æŒ‰éˆ•
        if st.button("Upload Files"):
            if uploaded_file is not None:
                data_folder = "data"
                # æª¢æŸ¥ data è³‡æ–™å¤¾æ˜¯å¦å­˜åœ¨ï¼Œå¦‚æœä¸å­˜åœ¨å‰‡å‰µå»º
                if not os.path.exists(data_folder):
                    os.makedirs(data_folder)
                
                # ä¿å­˜ä¸Šå‚³çš„æª”æ¡ˆ
                file_path = os.path.join(data_folder, uploaded_file.name)
                save_uploaded_file(uploaded_file, data_folder)
                st.success(f"Upload Sucessfully {file_path}")
            else:
                st.error("è«‹å…ˆé¸æ“‡ä¸€å€‹æª”æ¡ˆ")



        # æ·»åŠ æ¸…é™¤æŒ‰éˆ•
        if st.button("æ¸…é™¤ df_project"):
            st.session_state.df_project = None  # æ¸…é™¤æ•¸æ“š
            st.success("df_project å·²æˆåŠŸæ¸…é™¤ï¼")

        # é¡¯ç¤ºç•¶å‰ df_project ç‹€æ…‹ï¼ˆå¯é¸ï¼‰
        if st.session_state.df_project is not None:
            st.write("ç•¶å‰ df_projectï¼š")
            st.dataframe(st.session_state.df_project)
        else:
            st.write("df_project å·²è¢«æ¸…é™¤ã€‚")

def extract_main_view():
    col_today,col_page_title ,col_page = st.columns([9,1,2])
    with col_today:
        # ä½¿ç”¨ JavaScript é¡¯ç¤ºå³æ™‚æ™‚é–“
        js_code = """
        <div id="datetime" style="font-size: 16px;"></div>
        <script>
            function updateTime() {
                const now = new Date();
                const datetimeStr = now.toLocaleString('zh-TW', { 
                    year: 'numeric', 
                    month: '2-digit', 
                    day: '2-digit', 
                    hour: '2-digit', 
                    minute: '2-digit', 
                    second: '2-digit', 
                    hour12: false 
                });
                document.getElementById('datetime').innerText = 'Today: ' + datetimeStr;
            }
            updateTime();  // åˆæ¬¡åŸ·è¡Œ
            setInterval(updateTime, 1000);  // æ¯ç§’æ›´æ–°
        </script>
        """
        components.html(js_code, height=30)  # åµŒå…¥ HTML å’Œ JS
    with col_page_title:
        st.markdown('<div class="date-input-row page-title"><label>ğŸŒ</label></div>', unsafe_allow_html=True)
    with col_page:
        page_select = st.selectbox(
                        "ğŸŒ",
                        ("All","Setting"),
                        label_visibility = "collapsed"
                        )
    st.markdown(
        """
        <h4 style='
            text-align: center;
            background-color: #002b42;
            color: white;
            padding: 18px 10px;   /* ä¸Šä¸‹24pxã€å·¦å³10px */
            border-radius: 8px;
            box-shadow: 0 2px 5px rgba(0,0,0,0.3);
            margin-bottom: 1rem;
        '>LiG Taiwan Dashboard</h4>
        """,
        unsafe_allow_html=True
    )

    if "page" not in st.session_state:
        st.session_state.page = "All"

    if page_select == "All":
        st.session_state.page = "All"
    elif page_select == "Setting":
        st.session_state.page = "parameters"

    # Load the content based on current page
    if st.session_state.page == "All":
        all_projects()
    elif st.session_state.page == "parameters":
        parameters()
#====================================================
# 1) ç”¨æˆ¶ç™»éŒ„å‡½å¼
#====================================================
def login_api(username, password): # æ¨¡æ“¬çš„ API ç™»éŒ„å‡½æ•¸
    """æ¨¡æ“¬ API ç™»éŒ„è«‹æ±‚"""
    response = requests.post(
        f"{CORE_API_SERVER}/api/v1/login",
        data={
            "user[email]": username,
            "user[password]": password,
        },
        headers={"User-Agent": f"{DASHBOARD_AGENT}/0.1"},
    )
    if response.status_code == 200:
        token = response.json().get("token")
        expires_in = 28800  # 8 hour
        return token, expires_in  
    return None, None

def is_token_valid(token,expires_at):  # æª¢æŸ¥ Token çš„æœ‰æ•ˆæ€§
    """æª¢æŸ¥ Token æ˜¯å¦ä»æœ‰æ•ˆ"""
    response = requests.get(
        f"{CORE_API_SERVER}/logs/echo",
        headers = {'Authorization': 'Bearer ' + token, 
        'User-Agent': 'DashboardAgent/1.0'}
    )
    expired_check = datetime.now() < datetime.fromisoformat(expires_at)

    if not response.ok or not expired_check:
        return False
    return True

def save_token_to_file(token, expires_at, logged_in_user):
    """å°‡ Token å’ŒéæœŸæ™‚é–“ä¿å­˜åˆ°æœ¬åœ°æ–‡ä»¶"""
    token_filepath = os.path.join("data", TOKEN_FILE)
    try:
        # ç¢ºä¿ data ç›®éŒ„å­˜åœ¨
        os.makedirs("data", exist_ok=True)
        with open(token_filepath, "w") as f:
            json.dump({"token": token, "expires_at": expires_at, "logged_in_user": logged_in_user}, f)
        print(f"Saved token to {token_filepath}")
    except OSError as e:
        print(f"Failed to save token to {token_filepath}: {e}")
        st.error(f"ç„¡æ³•ä¿å­˜ token æ–‡ä»¶ï¼š{e}ï¼ˆå¯èƒ½æ˜¯ç£ç›¤ç©ºé–“ä¸è¶³ï¼‰")
        # å¯é¸ï¼šè¿”å› False è¡¨ç¤ºä¿å­˜å¤±æ•—
        return False
    return True

def load_token_from_file():  # å¾æœ¬åœ°æ–‡ä»¶åŠ è¼‰ Token
    """å¾æœ¬åœ°æ–‡ä»¶åŠ è¼‰ Token å’ŒéæœŸæ™‚é–“"""
    token_filepath = os.path.join("data", TOKEN_FILE)
    if os.path.exists(token_filepath):
        with open(token_filepath, "r") as f:
            data = json.load(f)
        return data.get("token"), data.get("expires_at"), data.get("logged_in_user", "")
    return None, None, None

def clear_token_file():  # æ¸…é™¤æœ¬åœ°æ–‡ä»¶ä¸­çš„ Token
    token_filepath = os.path.join("data", TOKEN_FILE)
    """æ¸…é™¤æœ¬åœ°æ–‡ä»¶ä¸­çš„ Token"""
    if os.path.exists(token_filepath):
        os.remove(token_filepath)

def login(): # ç™»éŒ„å‡½æ•¸
    """ç”¨æˆ¶ç™»éŒ„è™•ç†"""
    with st.form("login_form"):
        username = st.text_input("Username")
        password = st.text_input("Password", type="password")
        submit_button = st.form_submit_button("Login")

        if submit_button:
            token, expires_in = login_api(username, password)
            # å‘¼å«API ç²å– Tokenè·ŸéæœŸæ™‚é–“
            st.write(f'token: {token}')
            st.write(f'expires_in: {expires_in}')

            if token:
                #åŠ å¯† token
                expires_at = (datetime.now() + timedelta(seconds=expires_in)).isoformat()
                st.session_state["auth_token"] = token
                st.session_state["expires_at"] = expires_at
                st.session_state["logged_in_user"] = username
                save_token_to_file(token, expires_at, username)  # ä¿å­˜åˆ°æœ¬åœ°æ–‡ä»¶
                st.success("Login successful!")
                st.rerun()
            else:
                st.error("Invalid username or password.")

def logout(): # ç™»å‡ºå‡½æ•¸
    """è™•ç†ç”¨æˆ¶ç™»å‡º"""
    st.session_state["auth_token"] = ""
    st.session_state["expires_at"] = (datetime.now()).isoformat()
    st.session_state["logged_in_user"] = ""
    save_token_to_file("", (datetime.now()).isoformat(),"")
    st.success("Logged out!")
    st.rerun()

def check_login_status(): # æª¢æŸ¥ç™»å…¥ç‹€æ…‹
    """æª¢æŸ¥ç”¨æˆ¶æ˜¯å¦å·²ç™»å…¥"""
    # å¦‚æœ session ä¸­æ²’æœ‰ Tokenï¼Œå˜—è©¦å¾æ–‡ä»¶åŠ è¼‰
    if "auth_token" not in st.session_state or "logged_in_user" not in st.session_state:
        token, expires_at, logged_in_user = load_token_from_file()
        st.session_state["auth_token"] = token
        st.session_state["expires_at"] = expires_at
        st.session_state["logged_in_user"] = logged_in_user

    # å¦‚æœ Token ç„¡æ•ˆï¼Œè¦æ±‚é‡æ–°ç™»å…¥
    if not is_token_valid(st.session_state.get("auth_token"), st.session_state.get("expires_at")):
        st.session_state["auth_token"] = ""
        st.session_state["expires_at"] = (datetime.now()).isoformat()
        st.session_state["logged_in_user"] = ""
        login()
        st.stop()  # åœæ­¢åŸ·è¡Œå¾ŒçºŒä»£ç¢¼

#====================================================
# 2) Main()
#====================================================
def main():
    # print("your api host url is: ", os.getenv("API_HOST", None))
    # bypass the login page if the API_HOST is not set
    # if os.getenv("API_HOST", None):   

    initialize()
    check_dataframe(df_scan, "æƒææ•¸æ“š (df_scan)", ["scantime"])
    # check_dataframe(st.session_state.df_project, "å°ˆæ¡ˆæ•¸æ“š (df_project)", ["Project Name"])   
    token, expires_at, logged_in_user = load_token_from_file()
    # st.write(f'token: {token}')

    if is_token_valid(token,expires_at):
        st.session_state._lig_token = token
        st.session_state["logged_in_user"] = logged_in_user

    check_login_status()
    extract_main_view()

# %% Web App æ¸¬è©¦ (æª¢è¦–æˆæœ)  ============================================================================= ##
if __name__ == "__main__":
    main()
